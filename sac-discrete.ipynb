{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee72a878-fd03-493e-9bd3-b026eb77e7bf",
   "metadata": {},
   "source": [
    "### Рабочая версия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a39bf869-9184-4afd-9c03-58c003d336af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "from torch.distributions import Normal\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.distributions import RelaxedOneHotCategorical\n",
    "from torch.nn import KLDivLoss\n",
    "\n",
    "class SAC_discrete(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim, gamma=0.99, alpha=1.0, tau=0.5, \n",
    "                 batch_size=64, pi_lr=1e-3, q_lr=1e-3, a_lr=1e-4, period=15):\n",
    "        super().__init__()\n",
    "\n",
    "        self.pi_model = nn.Sequential(nn.Linear(state_dim, 64), nn.ReLU(), \n",
    "                                      nn.Linear(64, 64), nn.ReLU(), \n",
    "                                      nn.Linear(64, action_dim), nn.LogSoftmax(dim=1))\n",
    "        self.pi_model.name = \"policy\"\n",
    "\n",
    "        self.q1_model = nn.Sequential(nn.Linear(state_dim, 64), nn.ReLU(), \n",
    "                                      nn.Linear(64, 64), nn.ReLU(), \n",
    "                                      nn.Linear(64, action_dim))\n",
    "        self.q1_model.name = \"q1\"\n",
    "\n",
    "        self.q2_model = nn.Sequential(nn.Linear(state_dim, 64), nn.ReLU(), \n",
    "                                      nn.Linear(64, 64), nn.ReLU(), \n",
    "                                      nn.Linear(64, action_dim))\n",
    "        self.q2_model.name = \"q2\"\n",
    "\n",
    "        self.q1_layers_list = [self.q1_model[0], self.q1_model[2], self.q1_model[4]]\n",
    "        self.q2_layers_list = [self.q2_model[0], self.q2_model[2], self.q2_model[4]]\n",
    "        self.gamma = gamma\n",
    "        # self.alpha = alpha\n",
    "        self.tau = tau\n",
    "        self.batch_size = batch_size\n",
    "        self.memory = []\n",
    "        self.period = period\n",
    "        self.counter = 1\n",
    "        self.step = 1\n",
    "        self.state_dim = state_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.epoch_n = 2\n",
    "        self.q1_grads = []\n",
    "        self.q2_grads = []\n",
    "        \n",
    "\n",
    "        self.pi_optimizer = torch.optim.Adam(self.pi_model.parameters(), pi_lr)\n",
    "        # self.q_optimizer = torch.optim.Adam(self.q_model.parameters(), q_lr)\n",
    "        # self.q_target_model = deepcopy(self.q_model)\n",
    "        self.q1_optimizer = torch.optim.Adam(self.q1_model.parameters(), q_lr)\n",
    "        self.q2_optimizer = torch.optim.Adam(self.q2_model.parameters(), q_lr)\n",
    "        self.q1_target_model = deepcopy(self.q1_model)\n",
    "        self.q2_target_model = deepcopy(self.q2_model)\n",
    "\n",
    "        self.target_entropy = 0.98 * -np.log(1 / self.action_dim)\n",
    "        self.log_alpha = torch.tensor(np.log(alpha), requires_grad=True)\n",
    "        self.alpha = self.log_alpha\n",
    "        self.alpha_optimiser = torch.optim.Adam([self.log_alpha], lr=a_lr)\n",
    "\n",
    "    def get_action(self, state):\n",
    "        state = torch.FloatTensor(state).unsqueeze(0)\n",
    "        log_probs = self.pi_model(state)\n",
    "        if self.step % 200 == 0:\n",
    "            print(f'probs: {torch.exp(log_probs)}')\n",
    "            self.step += 1\n",
    "            print(f'alpha: {round(self.alpha.detach().numpy().reshape(-1)[0] , 2)}')\n",
    "        action = np.random.choice(np.arange(self.action_dim), p=torch.exp(log_probs).squeeze().detach().numpy())\n",
    "        return action\n",
    "\n",
    "    def add_five(self, state, action, reward, done, next_state):\n",
    "        self.memory.append([state, action, reward, int(done), next_state])\n",
    "    # дать накопить сначала около 10к значений в буфере а потом уже начинать обучаться\n",
    "    def fit(self):\n",
    "        if len(self.memory) >= self.batch_size + 100:\n",
    "            mean_q1_loss = []\n",
    "            mean_q2_loss = []\n",
    "            for i in range(self.epoch_n):\n",
    "                batch = random.sample(self.memory, self.batch_size)\n",
    "            \n",
    "                states, actions, rewards, dones, next_states = map(torch.FloatTensor, zip(*batch))\n",
    "                rewards, dones = rewards.unsqueeze(1), dones.unsqueeze(1)\n",
    "                # print(next_states)\n",
    "                \n",
    "                next_log_probs = self.pi_model(next_states)\n",
    "                # print(next_probs.shape)\n",
    "                next_probs = torch.exp(next_log_probs)\n",
    "                # print(next_log_probs.shape)\n",
    "                \n",
    "                # print(next_actions)\n",
    "                next_q1_values = self.q1_target_model(next_states)\n",
    "                next_q2_values = self.q2_target_model(next_states)\n",
    "                next_min_q_values = torch.min(next_q1_values, next_q2_values)\n",
    "                targets = rewards + self.gamma * (1 - dones) * torch.sum((next_min_q_values - self.alpha * next_log_probs) * next_probs, dim=1).unsqueeze(1)\n",
    "                # targets = rewards + self.gamma * (1 - dones) * torch.max(next_min_q_values, dim=1).values\n",
    "                # print((next_min_q_values - self.alpha * next_log_probs).shape)\n",
    "                # print(targets[0])\n",
    "                actions = actions.unsqueeze(1)\n",
    "                actions = torch.tensor(actions, dtype=torch.long)\n",
    "                # print(self.q1_model(states).gather(1, actions)[0])\n",
    "                # q_loss = torch.mean((self.q_model(states)[torch.arange(next_states.shape[0]), actions] - targets.detach()) ** 2)\n",
    "                q1_loss = torch.mean((self.q1_model(states).gather(1, actions) - targets.detach()) ** 2)\n",
    "                q2_loss = torch.mean((self.q2_model(states).gather(1, actions) - targets.detach()) ** 2)\n",
    "                if self.step % 100 == 0:\n",
    "                    print(f'q loss: {q1_loss.data.numpy()}')\n",
    "                # print(f'q_loss=\\n {q_loss.data.numpy()}')\n",
    "                mean_q1_loss.append(q1_loss.data.numpy())\n",
    "                mean_q2_loss.append(q2_loss.data.numpy())\n",
    "    \n",
    "                self.update_model(q1_loss, self.q1_optimizer, self.q1_model, self.q1_target_model)\n",
    "                self.update_model(q2_loss, self.q2_optimizer, self.q2_model, self.q2_target_model)\n",
    "\n",
    "                if i % 2 == 0:\n",
    "                    log_probs = self.pi_model(states)\n",
    "                    \n",
    "    \n",
    "                    q1_values = self.q1_model(states)\n",
    "                    q2_values = self.q2_model(states)\n",
    "                    min_q_values = torch.min(q1_values, q2_values)\n",
    "    \n",
    "                    pi_loss = torch.mean(torch.sum((self.alpha * log_probs - (min_q_values).detach()) * torch.exp(log_probs), dim=1) )\n",
    "                    if np.sum(pi_loss.data.numpy()) > 10:\n",
    "                        print('gradient explosion')\n",
    "                    if self.step % 100 == 0:\n",
    "                        print(f'pi loss: {pi_loss.data.numpy()}')\n",
    "    \n",
    "                    self.update_model(pi_loss, self.pi_optimizer, self.pi_model)\n",
    "\n",
    "                    alpha_loss = -(self.log_alpha * (log_probs + self.target_entropy).detach()).mean()\n",
    "                    alpha_loss.backward()\n",
    "                    self.alpha_optimiser.step()\n",
    "                    self.alpha = self.log_alpha.exp()\n",
    "                    self.alpha_optimiser.zero_grad()\n",
    "                \n",
    "                self.counter += 1\n",
    "                \n",
    "            self.step += 1\n",
    "\n",
    "            # for graphics\n",
    "            mean_q1_grads = np.mean(self.q1_grads)\n",
    "            self.q1_grads = []\n",
    "            mean_q2_grads = np.mean(self.q2_grads)\n",
    "            self.q2_grads = []\n",
    "            return np.mean(mean_q1_loss), np.mean(mean_q2_loss), mean_q1_grads, mean_q2_grads\n",
    "        else:\n",
    "            return 0, 0, 0, 0\n",
    "            \n",
    "    def update_model(self, loss, optimizer, model=None, target_model=None):\n",
    "        loss.backward()\n",
    "        if model.name == \"policy\":\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.1)\n",
    "        else:\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if model != None and target_model != None and self.counter % self.period == 0:\n",
    "            for param, target_param in zip(model.parameters(), target_model.parameters()):\n",
    "                new_target_param = (1 - self.tau) * target_param + self.tau * param\n",
    "                target_param.data.copy_(new_target_param)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f945823-1ce8-4130-aebc-312c316bbacf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/artem/base/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n",
      "/tmp/ipykernel_21507/1843719786.py:83: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)\n",
      "  states, actions, rewards, dones, next_states = map(torch.FloatTensor, zip(*batch))\n",
      "/tmp/ipykernel_21507/1843719786.py:101: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  actions = torch.tensor(actions, dtype=torch.long)\n",
      "/home/artem/base/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/artem/base/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.0\n",
      "18.666666666666668\n",
      "28.2\n",
      "28.428571428571427\n",
      "25.444444444444443\n",
      "24.7\n",
      "23.9\n",
      "24.4\n",
      "22.2\n",
      "21.6\n",
      "20.9\n",
      "20.9\n",
      "15.2\n",
      "q loss: 5.815148830413818\n",
      "pi loss: -9.546712875366211\n",
      "q loss: 2.5608153343200684\n",
      "14.9\n",
      "18.3\n",
      "19.6\n",
      "25.0\n",
      "25.7\n",
      "29.8\n",
      "28.8\n",
      "probs: tensor([[0.5269, 0.4731]], grad_fn=<ExpBackward0>)\n",
      "alpha: 1.02\n",
      "34.0\n",
      "39.8\n",
      "50.8\n",
      "q loss: 14.266655921936035\n",
      "pi loss: -23.971221923828125\n",
      "q loss: 6.0829572677612305\n",
      "65.1\n",
      "probs: tensor([[0.4818, 0.5182]], grad_fn=<ExpBackward0>)\n",
      "alpha: 1.02\n",
      "85.9\n",
      "q loss: 15.656146049499512\n",
      "pi loss: -35.964141845703125\n",
      "q loss: 14.59459400177002\n",
      "118.8\n",
      "probs: tensor([[0.5022, 0.4978]], grad_fn=<ExpBackward0>)\n",
      "alpha: 1.0\n",
      "q loss: 17.286117553710938\n",
      "pi loss: -49.13270568847656\n",
      "q loss: 5.336233139038086\n",
      "204.0\n",
      "probs: tensor([[0.8126, 0.1874]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.98\n",
      "q loss: 3.7267959117889404\n",
      "pi loss: -59.52619171142578\n",
      "q loss: 2.666745901107788\n",
      "263.8\n",
      "probs: tensor([[0.1782, 0.8218]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.96\n",
      "q loss: 1.1560957431793213\n",
      "pi loss: -70.5480728149414\n",
      "q loss: 32.04945373535156\n",
      "312.1\n",
      "probs: tensor([[0.0872, 0.9128]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.93\n",
      "335.5\n",
      "q loss: 1.9848469495773315\n",
      "pi loss: -79.8921127319336\n",
      "q loss: 1.1608893871307373\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m counter \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m4\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 29\u001b[0m     _mean_q1_loss, _mean_q2_loss, _mean_q1_grads, _mean_q2_grads \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     loss1\u001b[38;5;241m.\u001b[39mappend(_mean_q1_loss)\n\u001b[1;32m     31\u001b[0m     grads1\u001b[38;5;241m.\u001b[39mappend(_mean_q1_grads)\n",
      "Cell \u001b[0;32mIn[1], line 129\u001b[0m, in \u001b[0;36mSAC_discrete.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpi loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpi_loss\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 129\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpi_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpi_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpi_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m alpha_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_alpha \u001b[38;5;241m*\u001b[39m (log_probs \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_entropy)\u001b[38;5;241m.\u001b[39mdetach())\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m    132\u001b[0m alpha_loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "Cell \u001b[0;32mIn[1], line 157\u001b[0m, in \u001b[0;36mSAC_discrete.update_model\u001b[0;34m(self, loss, optimizer, model, target_model)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m     nn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[0;32m--> 157\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m target_model \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcounter \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mperiod \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/base/lib/python3.10/site-packages/torch/optim/optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    383\u001b[0m             )\n\u001b[0;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/base/lib/python3.10/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/base/lib/python3.10/site-packages/torch/optim/adam.py:166\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    155\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    157\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    158\u001b[0m         group,\n\u001b[1;32m    159\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    163\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    164\u001b[0m         state_steps)\n\u001b[0;32m--> 166\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/base/lib/python3.10/site-packages/torch/optim/adam.py:316\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    314\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 316\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m     \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/base/lib/python3.10/site-packages/torch/optim/adam.py:391\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    388\u001b[0m     param \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mview_as_real(param)\n\u001b[1;32m    390\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m--> 391\u001b[0m \u001b[43mexp_avg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlerp_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m exp_avg_sq\u001b[38;5;241m.\u001b[39mmul_(beta2)\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad\u001b[38;5;241m.\u001b[39mconj(), value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v1')\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.n\n",
    "\n",
    "agent = SAC_discrete(state_dim, action_dim)\n",
    "\n",
    "episode_n = 200\n",
    "\n",
    "total_rewards = []\n",
    "loss1 = []\n",
    "grads1 = []\n",
    "loss2 = []\n",
    "grads2 = []\n",
    "counter = 0\n",
    "for episode in range(episode_n):\n",
    "\n",
    "    total_reward = 0\n",
    "    state, info = env.reset()\n",
    "    \n",
    "    for i in range(1000):\n",
    "        action = agent.get_action(state)\n",
    "        \n",
    "        next_state, reward, terminated, truncated, info = env.step(action)\n",
    "        \n",
    "        agent.add_five(state, action, reward, terminated or truncated, next_state)\n",
    "        counter += 1\n",
    "\n",
    "        if counter % 4 == 0:\n",
    "            _mean_q1_loss, _mean_q2_loss, _mean_q1_grads, _mean_q2_grads = agent.fit()\n",
    "            loss1.append(_mean_q1_loss)\n",
    "            grads1.append(_mean_q1_grads)\n",
    "            loss2.append(_mean_q2_loss)\n",
    "            grads2.append(_mean_q2_grads)\n",
    "    \n",
    "        total_reward += reward\n",
    "        state = next_state\n",
    "\n",
    "        if terminated or truncated:\n",
    "            break\n",
    "\n",
    "    \n",
    "        \n",
    "    total_rewards.append(total_reward)\n",
    "    if episode % 2 == 0:\n",
    "        print(np.mean(total_rewards[-10:]))\n",
    "    \n",
    "\n",
    "plt.plot(total_rewards)\n",
    "plt.title('Total Rewards')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "plt.plot(loss1)\n",
    "plt.title('Q Loss1')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "plt.plot(grads1)\n",
    "plt.title('Q grads1')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "plt.plot(loss2)\n",
    "plt.title('Q Loss2')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "plt.plot(grads2)\n",
    "plt.title('Q grads2')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c8f8db21-1a37-46d4-ae43-4945ae158607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "from torch.distributions import Normal\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.distributions import RelaxedOneHotCategorical\n",
    "from torch.nn import KLDivLoss\n",
    "\n",
    "# torch.manual_seed(42)\n",
    "\n",
    "class SAC_discrete_for_lunar(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim, gamma=0.99, alpha=1.0, tau=0.8, \n",
    "                 batch_size=128, pi_lr=1e-3, q_lr=1e-3, a_lr=1e-5, period=10):\n",
    "        super().__init__()\n",
    "\n",
    "        self.pi_model = nn.Sequential(nn.Linear(state_dim, 64), nn.ReLU(), \n",
    "                                      nn.Linear(64, 64), nn.ReLU(), \n",
    "                                      nn.Linear(64, action_dim), nn.LogSoftmax(dim=1))\n",
    "        self.pi_model.name = \"policy\"\n",
    "\n",
    "        self.q1_model = nn.Sequential(nn.Linear(state_dim, 64), nn.ReLU(), \n",
    "                                      nn.Linear(64, 64), nn.ReLU(), \n",
    "                                      nn.Linear(64, action_dim))\n",
    "        self.q1_model.name = \"q1\"\n",
    "\n",
    "        self.q2_model = nn.Sequential(nn.Linear(state_dim, 64), nn.ReLU(), \n",
    "                                      nn.Linear(64, 64), nn.ReLU(), \n",
    "                                      nn.Linear(64, action_dim))\n",
    "        self.q2_model.name = \"q2\"\n",
    "\n",
    "        self.q1_layers_list = [self.q1_model[0], self.q1_model[2], self.q1_model[4]]\n",
    "        self.q2_layers_list = [self.q2_model[0], self.q2_model[2], self.q2_model[4]]\n",
    "        self.gamma = gamma\n",
    "        # self.alpha = alpha\n",
    "        self.tau = tau\n",
    "        self.batch_size = batch_size\n",
    "        self.memory = []\n",
    "        self.period = period\n",
    "        self.counter = 1\n",
    "        self.step = 1\n",
    "        self.state_dim = state_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.epoch_n = 1\n",
    "        self.q1_grads = []\n",
    "        self.q2_grads = []\n",
    "        \n",
    "\n",
    "        self.pi_optimizer = torch.optim.Adam(self.pi_model.parameters(), pi_lr)\n",
    "        # self.q_optimizer = torch.optim.Adam(self.q_model.parameters(), q_lr)\n",
    "        # self.q_target_model = deepcopy(self.q_model)\n",
    "        self.q1_optimizer = torch.optim.Adam(self.q1_model.parameters(), q_lr)\n",
    "        self.q2_optimizer = torch.optim.Adam(self.q2_model.parameters(), q_lr)\n",
    "        self.q1_target_model = deepcopy(self.q1_model)\n",
    "        self.q2_target_model = deepcopy(self.q2_model)\n",
    "\n",
    "        self.target_entropy = 0.98 * -np.log(1 / self.action_dim)\n",
    "        self.log_alpha = torch.tensor(np.log(alpha), requires_grad=True)\n",
    "        self.alpha = self.log_alpha\n",
    "        self.alpha_optimiser = torch.optim.Adam([self.log_alpha], lr=a_lr)\n",
    "\n",
    "    def get_action(self, state):\n",
    "        state = torch.FloatTensor(state).unsqueeze(0)\n",
    "        log_probs = self.pi_model(state)\n",
    "        if self.step % 300 == 0:\n",
    "            print(f'probs: {torch.exp(log_probs)}')\n",
    "            self.step += 1\n",
    "            print(f'alpha: {round(self.alpha.detach().numpy().reshape(-1)[0] , 2)}')\n",
    "        action = np.random.choice(np.arange(self.action_dim), p=torch.exp(log_probs).squeeze().detach().numpy())\n",
    "        return action\n",
    "\n",
    "    def add_five(self, state, action, reward, done, next_state):\n",
    "        self.memory.append([state, action, reward, int(done), next_state])\n",
    "    # дать накопить сначала около 10к значений в буфере а потом уже начинать обучаться\n",
    "    def fit(self):\n",
    "        if len(self.memory) >= self.batch_size + 100:\n",
    "            mean_q1_loss = []\n",
    "            mean_q2_loss = []\n",
    "            for i in range(self.epoch_n):\n",
    "                batch = random.sample(self.memory, self.batch_size)\n",
    "            \n",
    "                states, actions, rewards, dones, next_states = map(torch.FloatTensor, zip(*batch))\n",
    "                rewards, dones = rewards.unsqueeze(1), dones.unsqueeze(1)\n",
    "                # print(next_states)\n",
    "                \n",
    "                next_log_probs = self.pi_model(next_states)\n",
    "                # print(next_probs.shape)\n",
    "                next_probs = torch.exp(next_log_probs)\n",
    "                # print(next_log_probs.shape)\n",
    "                \n",
    "                # print(next_actions)\n",
    "                next_q1_values = self.q1_target_model(next_states)\n",
    "                next_q2_values = self.q2_target_model(next_states)\n",
    "                next_min_q_values = torch.min(next_q1_values, next_q2_values)\n",
    "                targets = rewards + self.gamma * (1 - dones) * torch.sum((next_min_q_values - self.alpha * next_log_probs) * next_probs, dim=1).unsqueeze(1)\n",
    "                # targets = rewards + self.gamma * (1 - dones) * torch.max(next_min_q_values, dim=1).values\n",
    "                # print((next_min_q_values - self.alpha * next_log_probs).shape)\n",
    "                # print(targets[0])\n",
    "                actions = actions.unsqueeze(1)\n",
    "                actions = torch.tensor(actions, dtype=torch.long)\n",
    "                # print(self.q1_model(states).gather(1, actions)[0])\n",
    "                # q_loss = torch.mean((self.q_model(states)[torch.arange(next_states.shape[0]), actions] - targets.detach()) ** 2)\n",
    "                q1_loss = torch.mean((self.q1_model(states).gather(1, actions) - targets.detach()) ** 2)\n",
    "                q2_loss = torch.mean((self.q2_model(states).gather(1, actions) - targets.detach()) ** 2)\n",
    "                if self.step % 300 == 0:\n",
    "                    print(f'q loss: {q1_loss.data.numpy()}')\n",
    "                # print(f'q_loss=\\n {q_loss.data.numpy()}')\n",
    "                mean_q1_loss.append(q1_loss.data.numpy())\n",
    "                mean_q2_loss.append(q2_loss.data.numpy())\n",
    "    \n",
    "                self.update_model(q1_loss, self.q1_optimizer, self.q1_model, self.q1_target_model)\n",
    "                self.update_model(q2_loss, self.q2_optimizer, self.q2_model, self.q2_target_model)\n",
    "\n",
    "                if i % 2 == 0:\n",
    "                    log_probs = self.pi_model(states)\n",
    "                    \n",
    "                    q1_values = self.q1_model(states)\n",
    "                    q2_values = self.q2_model(states)\n",
    "                    min_q_values = torch.min(q1_values, q2_values)\n",
    "    \n",
    "                    pi_loss = torch.mean(torch.sum((self.alpha * log_probs - (min_q_values).detach()) * torch.exp(log_probs), dim=1) )\n",
    "                    if self.step % 300 == 0:\n",
    "                        print(f'pi loss: {pi_loss.data.numpy()}')\n",
    "    \n",
    "                    self.update_model(pi_loss, self.pi_optimizer, self.pi_model)\n",
    "\n",
    "                    alpha_loss = -(self.log_alpha * (log_probs + self.target_entropy).detach()).mean()\n",
    "                    alpha_loss.backward()\n",
    "                    self.alpha_optimiser.step()\n",
    "                    self.alpha = self.log_alpha.exp()\n",
    "                    self.alpha_optimiser.zero_grad()\n",
    "                \n",
    "                self.counter += 1\n",
    "                \n",
    "            self.step += 1\n",
    "\n",
    "            # for graphics\n",
    "            mean_q1_grads = np.mean(self.q1_grads)\n",
    "            self.q1_grads = []\n",
    "            mean_q2_grads = np.mean(self.q2_grads)\n",
    "            self.q2_grads = []\n",
    "            return np.mean(mean_q1_loss), np.mean(mean_q2_loss), mean_q1_grads, mean_q2_grads\n",
    "        else:\n",
    "            return 0, 0, 0, 0\n",
    "            \n",
    "    def update_model(self, loss, optimizer, model=None, target_model=None):\n",
    "        loss.backward()\n",
    "        if model.name == \"policy\":\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        else:\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if model != None and target_model != None and self.counter % self.period == 0:\n",
    "            for param, target_param in zip(model.parameters(), target_model.parameters()):\n",
    "                new_target_param = (1 - self.tau) * target_param + self.tau * param\n",
    "                target_param.data.copy_(new_target_param)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b68a782c-f39d-4e1f-b183-1a7f915ce25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-125.63761473120749\n",
      "-124.96629523190167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10473/3285244228.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  actions = torch.tensor(actions, dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-171.95003666644132\n",
      "probs: tensor([[0.1134, 0.0830, 0.7140, 0.0896]], grad_fn=<ExpBackward0>)\n",
      "alpha: 1.0\n",
      "probs: tensor([[0.4744, 0.1812, 0.1813, 0.1631]], grad_fn=<ExpBackward0>)\n",
      "alpha: 1.0\n",
      "-216.1755868260465\n",
      "probs: tensor([[0.1389, 0.0497, 0.0913, 0.7201]], grad_fn=<ExpBackward0>)\n",
      "alpha: 1.0\n",
      "-209.41862150234704\n",
      "probs: tensor([[0.1122, 0.1880, 0.5462, 0.1536]], grad_fn=<ExpBackward0>)\n",
      "alpha: 1.0\n",
      "-193.98354557585156\n",
      "probs: tensor([[0.1558, 0.6627, 0.1758, 0.0056]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.99\n",
      "probs: tensor([[0.2195, 0.1123, 0.3861, 0.2821]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.99\n",
      "probs: tensor([[0.2466, 0.1284, 0.5218, 0.1032]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.99\n",
      "probs: tensor([[0.1074, 0.1828, 0.5708, 0.1390]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.98\n",
      "-182.45436787621207\n",
      "probs: tensor([[0.2400, 0.2874, 0.4134, 0.0592]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.98\n",
      "probs: tensor([[0.1175, 0.0558, 0.4161, 0.4106]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.98\n",
      "probs: tensor([[0.1449, 0.1969, 0.5912, 0.0670]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.98\n",
      "probs: tensor([[1.3149e-04, 1.7755e-01, 8.2231e-01, 1.0635e-05]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.97\n",
      "probs: tensor([[4.0100e-02, 2.7702e-05, 1.3810e-01, 8.2178e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.97\n",
      "-145.93808962601872\n",
      "probs: tensor([[0.1387, 0.1426, 0.5984, 0.1202]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.97\n",
      "probs: tensor([[0.3001, 0.0840, 0.4243, 0.1916]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.96\n",
      "probs: tensor([[0.0676, 0.0245, 0.6190, 0.2889]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.96\n",
      "probs: tensor([[0.0802, 0.0181, 0.7344, 0.1673]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.96\n",
      "probs: tensor([[0.1919, 0.1066, 0.5567, 0.1448]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.96\n",
      "-97.3027703821476\n",
      "probs: tensor([[0.3238, 0.1213, 0.4219, 0.1330]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.95\n",
      "probs: tensor([[0.1783, 0.1415, 0.5428, 0.1374]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.95\n",
      "probs: tensor([[0.2141, 0.2165, 0.4485, 0.1209]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.95\n",
      "probs: tensor([[0.0343, 0.0406, 0.8372, 0.0880]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.94\n",
      "probs: tensor([[0.0794, 0.3610, 0.5441, 0.0156]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.94\n",
      "probs: tensor([[0.2474, 0.2016, 0.4289, 0.1222]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.94\n",
      "-68.32465606491658\n",
      "probs: tensor([[0.4601, 0.2474, 0.0376, 0.2549]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.94\n",
      "probs: tensor([[0.0799, 0.1390, 0.6997, 0.0814]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.94\n",
      "probs: tensor([[0.0623, 0.0434, 0.8350, 0.0593]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.93\n",
      "probs: tensor([[5.3248e-01, 8.5635e-05, 5.1955e-05, 4.6738e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.93\n",
      "probs: tensor([[0.1609, 0.0983, 0.5572, 0.1836]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.93\n",
      "probs: tensor([[0.1584, 0.0518, 0.4875, 0.3023]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.93\n",
      "-17.287571859658918\n",
      "probs: tensor([[0.2623, 0.2052, 0.3787, 0.1537]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.93\n",
      "probs: tensor([[0.0669, 0.0809, 0.8158, 0.0364]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.92\n",
      "probs: tensor([[0.1918, 0.1071, 0.5040, 0.1971]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.92\n",
      "probs: tensor([[0.1124, 0.0859, 0.6773, 0.1244]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.92\n",
      "probs: tensor([[0.1122, 0.0196, 0.5419, 0.3263]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.92\n",
      "probs: tensor([[0.1414, 0.2110, 0.5647, 0.0829]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.92\n",
      "probs: tensor([[8.2833e-01, 1.4345e-03, 1.8829e-04, 1.7004e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.91\n",
      "-3.5575061201107347\n",
      "probs: tensor([[0.1552, 0.0699, 0.5309, 0.2439]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.91\n",
      "probs: tensor([[0.0665, 0.2840, 0.6346, 0.0148]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.91\n",
      "probs: tensor([[0.1059, 0.0443, 0.6839, 0.1659]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.91\n",
      "probs: tensor([[5.1878e-01, 1.4590e-05, 3.5262e-05, 4.8117e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.9\n",
      "probs: tensor([[0.0815, 0.1249, 0.7493, 0.0443]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.9\n",
      "42.065726853561095\n",
      "probs: tensor([[0.1401, 0.2663, 0.5403, 0.0533]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.9\n",
      "probs: tensor([[0.2043, 0.1630, 0.5209, 0.1119]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.9\n",
      "probs: tensor([[9.0548e-02, 8.5034e-05, 3.0468e-03, 9.0632e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.89\n",
      "probs: tensor([[0.1376, 0.1006, 0.6381, 0.1238]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.89\n",
      "probs: tensor([[0.6467, 0.0011, 0.0112, 0.3410]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.89\n",
      "probs: tensor([[0.7461, 0.0012, 0.0126, 0.2401]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.88\n",
      "86.7364483927118\n",
      "probs: tensor([[0.1346, 0.2395, 0.5773, 0.0486]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.88\n",
      "probs: tensor([[0.1082, 0.0620, 0.7070, 0.1228]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.88\n",
      "probs: tensor([[0.1405, 0.0822, 0.6922, 0.0851]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.88\n",
      "probs: tensor([[0.0783, 0.0406, 0.8364, 0.0447]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.87\n",
      "98.06062842719362\n",
      "probs: tensor([[0.1363, 0.1408, 0.6603, 0.0626]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.87\n",
      "probs: tensor([[0.1503, 0.2276, 0.5373, 0.0848]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.87\n",
      "probs: tensor([[0.0678, 0.0967, 0.8044, 0.0311]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.86\n",
      "probs: tensor([[0.1390, 0.0977, 0.7025, 0.0608]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.86\n",
      "probs: tensor([[0.1267, 0.2012, 0.6246, 0.0476]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.86\n",
      "probs: tensor([[0.0978, 0.1967, 0.6657, 0.0399]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.86\n",
      "probs: tensor([[7.9878e-01, 1.2394e-04, 4.4913e-04, 2.0065e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.85\n",
      "89.87737176455008\n",
      "probs: tensor([[0.2314, 0.1664, 0.4589, 0.1433]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.85\n",
      "probs: tensor([[0.0967, 0.0413, 0.7784, 0.0835]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.85\n",
      "probs: tensor([[7.5769e-01, 2.7759e-04, 5.7434e-03, 2.3628e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.85\n",
      "probs: tensor([[0.0835, 0.0500, 0.7460, 0.1206]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.84\n",
      "probs: tensor([[0.2845, 0.2011, 0.3293, 0.1850]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.84\n",
      "probs: tensor([[6.8081e-01, 3.5140e-04, 4.7053e-03, 3.1414e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.84\n",
      "94.56485429709663\n",
      "probs: tensor([[0.1603, 0.1494, 0.5907, 0.0997]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.84\n",
      "probs: tensor([[0.0416, 0.0341, 0.9005, 0.0237]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.84\n",
      "probs: tensor([[0.1833, 0.0318, 0.5564, 0.2285]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.83\n",
      "probs: tensor([[5.7247e-01, 1.4268e-05, 1.7571e-05, 4.2750e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.83\n",
      "probs: tensor([[0.0556, 0.0341, 0.8473, 0.0630]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.83\n",
      "probs: tensor([[0.0978, 0.0505, 0.7734, 0.0783]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.83\n",
      "probs: tensor([[3.9234e-01, 2.9710e-05, 2.6666e-03, 6.0497e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.82\n",
      "64.52835453331554\n",
      "probs: tensor([[0.2283, 0.2784, 0.3451, 0.1482]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.82\n",
      "probs: tensor([[0.2530, 0.1425, 0.3641, 0.2405]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.82\n",
      "probs: tensor([[0.1005, 0.0567, 0.7855, 0.0574]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.82\n",
      "probs: tensor([[0.2799, 0.2625, 0.3654, 0.0922]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.82\n",
      "probs: tensor([[0.2907, 0.1537, 0.3216, 0.2340]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.81\n",
      "probs: tensor([[0.1085, 0.1146, 0.7419, 0.0350]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.81\n",
      "probs: tensor([[0.1850, 0.6039, 0.1549, 0.0561]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.81\n",
      "34.14704376416436\n",
      "probs: tensor([[0.2599, 0.0719, 0.2858, 0.3825]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.81\n",
      "probs: tensor([[0.2099, 0.1569, 0.4344, 0.1987]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.81\n",
      "probs: tensor([[0.0768, 0.0682, 0.7633, 0.0917]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.8\n",
      "probs: tensor([[0.1827, 0.0371, 0.3752, 0.4049]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.8\n",
      "probs: tensor([[0.1892, 0.0905, 0.5242, 0.1961]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.8\n",
      "probs: tensor([[0.5901, 0.0015, 0.0104, 0.3981]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.8\n",
      "45.718825722805924\n",
      "probs: tensor([[0.3456, 0.1387, 0.0256, 0.4901]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.8\n",
      "probs: tensor([[0.1496, 0.1132, 0.5286, 0.2087]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.79\n",
      "probs: tensor([[0.2209, 0.4571, 0.2305, 0.0915]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.79\n",
      "probs: tensor([[0.1342, 0.1065, 0.5906, 0.1688]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.79\n",
      "probs: tensor([[0.0681, 0.1064, 0.7870, 0.0385]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.79\n",
      "probs: tensor([[0.0833, 0.0567, 0.8042, 0.0558]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.78\n",
      "probs: tensor([[0.1735, 0.3254, 0.3741, 0.1270]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.78\n",
      "15.421810737353772\n",
      "probs: tensor([[0.1538, 0.4057, 0.3999, 0.0407]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.78\n",
      "probs: tensor([[0.1935, 0.3013, 0.4368, 0.0684]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.78\n",
      "probs: tensor([[0.1424, 0.1273, 0.6340, 0.0963]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.78\n",
      "probs: tensor([[0.1355, 0.0576, 0.6606, 0.1464]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.77\n",
      "probs: tensor([[0.2691, 0.0490, 0.3053, 0.3765]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.77\n",
      "probs: tensor([[0.1148, 0.0636, 0.7619, 0.0596]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.77\n",
      "probs: tensor([[0.1353, 0.0510, 0.6608, 0.1529]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.77\n",
      "7.590981689200312\n",
      "probs: tensor([[0.0568, 0.0489, 0.8660, 0.0283]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.77\n",
      "probs: tensor([[0.1719, 0.0696, 0.4487, 0.3098]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.76\n",
      "probs: tensor([[0.1002, 0.1806, 0.6898, 0.0294]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.76\n",
      "probs: tensor([[0.0993, 0.1296, 0.7126, 0.0586]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.76\n",
      "probs: tensor([[0.1162, 0.0307, 0.4792, 0.3740]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.76\n",
      "probs: tensor([[0.0840, 0.0466, 0.7941, 0.0753]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.76\n",
      "probs: tensor([[0.6066, 0.0478, 0.0114, 0.3342]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.76\n",
      "12.908898729034348\n",
      "probs: tensor([[0.0671, 0.1616, 0.7476, 0.0236]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.75\n",
      "probs: tensor([[0.2812, 0.2115, 0.1663, 0.3411]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.75\n",
      "probs: tensor([[0.6735, 0.0354, 0.0011, 0.2900]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.75\n",
      "probs: tensor([[0.2596, 0.3237, 0.3071, 0.1096]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.75\n",
      "probs: tensor([[0.1858, 0.0594, 0.5231, 0.2317]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.74\n",
      "probs: tensor([[0.1778, 0.0450, 0.4916, 0.2856]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.74\n",
      "17.362802389099894\n",
      "probs: tensor([[0.1132, 0.0308, 0.8309, 0.0251]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.74\n",
      "probs: tensor([[0.2849, 0.5815, 0.0451, 0.0886]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.74\n",
      "probs: tensor([[0.1051, 0.2020, 0.6639, 0.0290]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.74\n",
      "probs: tensor([[0.1560, 0.0704, 0.6022, 0.1714]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.73\n",
      "probs: tensor([[0.2792, 0.1593, 0.3217, 0.2398]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.73\n",
      "probs: tensor([[0.0951, 0.0225, 0.6616, 0.2209]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.73\n",
      "probs: tensor([[0.0828, 0.0210, 0.7695, 0.1267]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.73\n",
      "8.586546091763967\n",
      "probs: tensor([[0.1375, 0.0338, 0.5052, 0.3235]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.73\n",
      "probs: tensor([[0.1081, 0.0172, 0.5535, 0.3211]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.72\n",
      "probs: tensor([[0.0785, 0.1439, 0.7483, 0.0293]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.72\n",
      "probs: tensor([[0.1546, 0.1167, 0.5587, 0.1700]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.72\n",
      "probs: tensor([[0.2566, 0.1660, 0.3676, 0.2099]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.72\n",
      "probs: tensor([[0.1573, 0.0443, 0.5275, 0.2709]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.72\n",
      "probs: tensor([[0.1637, 0.0876, 0.5886, 0.1600]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.72\n",
      "14.400726129435895\n",
      "probs: tensor([[0.2597, 0.1288, 0.3901, 0.2213]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.71\n",
      "probs: tensor([[0.0621, 0.1005, 0.8181, 0.0193]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.71\n",
      "probs: tensor([[0.0517, 0.0196, 0.8889, 0.0398]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.71\n",
      "probs: tensor([[0.1488, 0.3223, 0.4841, 0.0448]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.71\n",
      "probs: tensor([[0.1374, 0.1087, 0.6720, 0.0819]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.7\n",
      "probs: tensor([[0.5605, 0.1664, 0.0043, 0.2689]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.7\n",
      "33.506457546977835\n",
      "probs: tensor([[0.1682, 0.1442, 0.5392, 0.1484]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.7\n",
      "probs: tensor([[0.2382, 0.2057, 0.4523, 0.1038]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.7\n",
      "probs: tensor([[0.2042, 0.1550, 0.4951, 0.1457]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.7\n",
      "probs: tensor([[0.5289, 0.3013, 0.0006, 0.1692]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.7\n",
      "probs: tensor([[0.1379, 0.3592, 0.4725, 0.0304]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.69\n",
      "probs: tensor([[0.1448, 0.1042, 0.6428, 0.1082]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.69\n",
      "probs: tensor([[0.1994, 0.2461, 0.4571, 0.0974]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.69\n",
      "33.7178388211683\n",
      "probs: tensor([[0.0944, 0.0163, 0.6391, 0.2501]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.69\n",
      "probs: tensor([[0.2134, 0.0798, 0.4468, 0.2600]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.69\n",
      "probs: tensor([[0.2785, 0.3714, 0.1944, 0.1556]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.68\n",
      "probs: tensor([[0.0768, 0.0505, 0.8212, 0.0515]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.68\n",
      "probs: tensor([[0.1032, 0.0817, 0.7518, 0.0634]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.68\n",
      "probs: tensor([[0.0556, 0.0063, 0.7735, 0.1646]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.68\n",
      "probs: tensor([[0.4616, 0.2653, 0.0014, 0.2717]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.68\n",
      "37.59501463465831\n",
      "probs: tensor([[0.0813, 0.0570, 0.8108, 0.0508]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.67\n",
      "probs: tensor([[0.3021, 0.3182, 0.1806, 0.1991]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.67\n",
      "probs: tensor([[0.2095, 0.1624, 0.4783, 0.1498]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.67\n",
      "probs: tensor([[0.1106, 0.3926, 0.4667, 0.0301]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.67\n",
      "probs: tensor([[0.0436, 0.0071, 0.8999, 0.0494]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.67\n",
      "probs: tensor([[0.2946, 0.0874, 0.2523, 0.3656]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.66\n",
      "45.33823974265693\n",
      "probs: tensor([[0.1551, 0.3003, 0.4881, 0.0565]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.66\n",
      "probs: tensor([[0.4016, 0.0925, 0.0959, 0.4100]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.66\n",
      "probs: tensor([[0.1512, 0.0637, 0.6222, 0.1630]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.66\n",
      "probs: tensor([[0.1563, 0.0254, 0.1510, 0.6673]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.66\n",
      "probs: tensor([[0.1458, 0.4695, 0.3700, 0.0148]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.66\n",
      "probs: tensor([[0.0888, 0.2170, 0.6722, 0.0220]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.65\n",
      "probs: tensor([[0.2013, 0.2765, 0.4701, 0.0521]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.65\n",
      "43.03639773437796\n",
      "probs: tensor([[0.1473, 0.1698, 0.6040, 0.0789]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.65\n",
      "probs: tensor([[0.1425, 0.0619, 0.6556, 0.1400]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.65\n",
      "probs: tensor([[0.3230, 0.2666, 0.1346, 0.2758]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.65\n",
      "probs: tensor([[0.2285, 0.2057, 0.3876, 0.1783]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.64\n",
      "probs: tensor([[0.1178, 0.0248, 0.6665, 0.1909]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.64\n",
      "probs: tensor([[0.1110, 0.0389, 0.7305, 0.1195]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.64\n",
      "probs: tensor([[0.4906, 0.1134, 0.0060, 0.3900]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.64\n",
      "39.01475027116002\n",
      "probs: tensor([[0.1379, 0.1788, 0.6172, 0.0661]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.64\n",
      "probs: tensor([[0.1044, 0.0487, 0.7570, 0.0900]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.64\n",
      "probs: tensor([[0.1824, 0.1277, 0.5286, 0.1613]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.63\n",
      "probs: tensor([[0.2774, 0.1347, 0.2990, 0.2889]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.63\n",
      "probs: tensor([[0.2518, 0.0735, 0.3156, 0.3592]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.63\n",
      "probs: tensor([[0.0576, 0.0070, 0.7301, 0.2053]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.63\n",
      "36.468344054364124\n",
      "probs: tensor([[0.1428, 0.0290, 0.2675, 0.5607]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.63\n",
      "probs: tensor([[0.1285, 0.0311, 0.6942, 0.1463]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.62\n",
      "probs: tensor([[0.4780, 0.3115, 0.0027, 0.2078]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.62\n",
      "probs: tensor([[0.5371, 0.2793, 0.0009, 0.1827]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.62\n",
      "probs: tensor([[0.2239, 0.3204, 0.3907, 0.0650]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.62\n",
      "probs: tensor([[0.2782, 0.2100, 0.3349, 0.1769]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.62\n",
      "probs: tensor([[0.5960, 0.1782, 0.0009, 0.2249]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.62\n",
      "48.885313673718855\n",
      "probs: tensor([[0.1158, 0.0472, 0.6568, 0.1802]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.62\n",
      "probs: tensor([[0.1787, 0.0239, 0.1117, 0.6857]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.62\n",
      "probs: tensor([[0.3186, 0.0342, 0.0178, 0.6294]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.61\n",
      "probs: tensor([[4.0573e-01, 1.4876e-01, 3.9344e-04, 4.4512e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.61\n",
      "probs: tensor([[0.3279, 0.2499, 0.2681, 0.1542]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.61\n",
      "probs: tensor([[0.3671, 0.1914, 0.1705, 0.2710]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.61\n",
      "probs: tensor([[0.5461, 0.2399, 0.0120, 0.2020]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.61\n",
      "48.29197647636528\n",
      "probs: tensor([[0.2603, 0.4481, 0.1532, 0.1384]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.61\n",
      "probs: tensor([[0.5495, 0.3061, 0.0026, 0.1419]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.6\n",
      "probs: tensor([[0.5985, 0.1746, 0.0051, 0.2218]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.6\n",
      "probs: tensor([[0.1929, 0.1261, 0.3958, 0.2852]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.6\n",
      "probs: tensor([[0.2103, 0.0682, 0.4163, 0.3053]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.6\n",
      "probs: tensor([[0.5628, 0.2727, 0.0007, 0.1637]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.6\n",
      "70.69461077277899\n",
      "probs: tensor([[1.4135e-01, 8.5360e-01, 5.2362e-06, 5.0516e-03]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.6\n",
      "probs: tensor([[0.1639, 0.1017, 0.6310, 0.1034]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.59\n",
      "probs: tensor([[0.1059, 0.0355, 0.7005, 0.1581]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.59\n",
      "probs: tensor([[0.4659, 0.3546, 0.0041, 0.1753]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.59\n",
      "probs: tensor([[0.1871, 0.0701, 0.5178, 0.2250]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.59\n",
      "probs: tensor([[0.5238, 0.2867, 0.0017, 0.1878]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.59\n",
      "probs: tensor([[0.4202, 0.3146, 0.0028, 0.2625]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.59\n",
      "76.17258903233096\n",
      "probs: tensor([[0.2521, 0.0349, 0.2446, 0.4684]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.58\n",
      "probs: tensor([[0.1514, 0.0523, 0.6341, 0.1621]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.58\n",
      "probs: tensor([[5.0036e-01, 3.2930e-01, 1.5025e-04, 1.7019e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.58\n",
      "probs: tensor([[4.3988e-01, 3.5635e-01, 2.9896e-04, 2.0347e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.58\n",
      "probs: tensor([[0.1203, 0.2739, 0.5729, 0.0329]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.58\n",
      "probs: tensor([[0.5194, 0.1333, 0.0077, 0.3396]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.58\n",
      "probs: tensor([[0.4717, 0.1724, 0.0024, 0.3534]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.57\n",
      "97.97181824885752\n",
      "probs: tensor([[0.1246, 0.0777, 0.6842, 0.1134]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.57\n",
      "probs: tensor([[3.2662e-01, 5.3305e-01, 3.9836e-04, 1.3994e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.57\n",
      "probs: tensor([[8.9070e-01, 5.8979e-06, 5.8286e-08, 1.0930e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.57\n",
      "probs: tensor([[0.1445, 0.0590, 0.6656, 0.1310]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.57\n",
      "probs: tensor([[0.1812, 0.0458, 0.4879, 0.2851]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.57\n",
      "probs: tensor([[0.0854, 0.0202, 0.7381, 0.1564]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.56\n",
      "103.45792117536489\n",
      "probs: tensor([[0.1075, 0.1814, 0.6695, 0.0416]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.56\n",
      "probs: tensor([[0.2989, 0.1066, 0.3476, 0.2469]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.56\n",
      "probs: tensor([[0.1875, 0.0190, 0.3391, 0.4544]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.56\n",
      "probs: tensor([[0.1408, 0.8255, 0.0229, 0.0107]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.56\n",
      "probs: tensor([[0.1748, 0.1399, 0.5593, 0.1260]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.56\n",
      "probs: tensor([[0.5482, 0.2286, 0.0014, 0.2218]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.55\n",
      "probs: tensor([[5.9022e-01, 2.8940e-01, 1.4067e-04, 1.2023e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.55\n",
      "109.10184850657079\n",
      "probs: tensor([[0.0831, 0.0813, 0.8061, 0.0294]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.55\n",
      "probs: tensor([[4.8723e-01, 3.1293e-01, 4.6667e-04, 1.9937e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.55\n",
      "probs: tensor([[0.5271, 0.3050, 0.0012, 0.1667]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.55\n",
      "probs: tensor([[0.1921, 0.0649, 0.5458, 0.1973]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.55\n",
      "probs: tensor([[0.1013, 0.1864, 0.6653, 0.0470]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.54\n",
      "probs: tensor([[5.6834e-01, 2.8724e-01, 1.3611e-04, 1.4428e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.54\n",
      "probs: tensor([[0.5589, 0.2510, 0.0009, 0.1892]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.54\n",
      "112.32480509201915\n",
      "probs: tensor([[0.1589, 0.0248, 0.4865, 0.3299]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.54\n",
      "probs: tensor([[0.0466, 0.0897, 0.8454, 0.0183]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.54\n",
      "probs: tensor([[0.5365, 0.2480, 0.0025, 0.2130]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.54\n",
      "probs: tensor([[0.0461, 0.0324, 0.8792, 0.0423]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.54\n",
      "probs: tensor([[0.2205, 0.2549, 0.4421, 0.0825]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.53\n",
      "probs: tensor([[5.4047e-03, 9.6721e-06, 9.5204e-01, 4.2546e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.53\n",
      "102.1649597210233\n",
      "probs: tensor([[0.1451, 0.0711, 0.6481, 0.1357]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.53\n",
      "probs: tensor([[0.0803, 0.0127, 0.6769, 0.2301]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.53\n",
      "probs: tensor([[0.3035, 0.0958, 0.3710, 0.2297]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.53\n",
      "probs: tensor([[3.0259e-01, 5.9985e-01, 6.6040e-05, 9.7494e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.53\n",
      "probs: tensor([[0.1270, 0.0212, 0.5775, 0.2744]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.52\n",
      "probs: tensor([[0.1692, 0.0945, 0.6132, 0.1232]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.52\n",
      "probs: tensor([[5.2309e-01, 2.7935e-01, 5.0563e-05, 1.9751e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.52\n",
      "83.2470756549643\n",
      "probs: tensor([[0.2121, 0.3047, 0.4348, 0.0483]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.52\n",
      "probs: tensor([[0.0409, 0.0685, 0.8741, 0.0165]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.52\n",
      "probs: tensor([[5.2400e-01, 2.5643e-01, 1.2701e-04, 2.1945e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.52\n",
      "probs: tensor([[0.0807, 0.0226, 0.8374, 0.0593]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.51\n",
      "probs: tensor([[0.1059, 0.2544, 0.6203, 0.0194]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.51\n",
      "probs: tensor([[0.2013, 0.0161, 0.2296, 0.5529]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.51\n",
      "probs: tensor([[0.1113, 0.1196, 0.7238, 0.0453]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.51\n",
      "67.24307337208717\n",
      "probs: tensor([[0.2822, 0.1519, 0.3205, 0.2454]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.51\n",
      "probs: tensor([[0.1534, 0.0490, 0.5391, 0.2585]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.51\n",
      "probs: tensor([[5.2384e-01, 2.3639e-01, 4.9276e-05, 2.3972e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.5\n",
      "probs: tensor([[0.2334, 0.0713, 0.4255, 0.2698]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.5\n",
      "probs: tensor([[0.1877, 0.0760, 0.6124, 0.1239]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.5\n",
      "probs: tensor([[0.0431, 0.0165, 0.8903, 0.0501]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.5\n",
      "57.09661913054278\n",
      "probs: tensor([[0.1484, 0.0552, 0.5409, 0.2554]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.5\n",
      "probs: tensor([[0.0808, 0.0221, 0.7212, 0.1758]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.5\n",
      "probs: tensor([[0.0785, 0.0682, 0.8065, 0.0468]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.5\n",
      "probs: tensor([[0.2411, 0.0252, 0.1152, 0.6185]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.49\n",
      "probs: tensor([[0.1166, 0.1338, 0.7050, 0.0445]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.49\n",
      "probs: tensor([[0.0865, 0.0510, 0.8031, 0.0594]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.49\n",
      "probs: tensor([[5.1270e-01, 2.2081e-01, 1.4164e-04, 2.6634e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.49\n",
      "36.841716443044994\n",
      "probs: tensor([[0.0671, 0.0458, 0.7527, 0.1344]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.49\n",
      "probs: tensor([[2.4398e-01, 7.3396e-01, 2.8329e-06, 2.2055e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.49\n",
      "probs: tensor([[0.4755, 0.3047, 0.0005, 0.2194]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.49\n",
      "probs: tensor([[0.1519, 0.0862, 0.6229, 0.1389]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.48\n",
      "probs: tensor([[5.7450e-01, 2.2154e-01, 1.7715e-05, 2.0395e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.48\n",
      "probs: tensor([[5.9196e-01, 2.8687e-01, 6.2894e-06, 1.2117e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.48\n",
      "probs: tensor([[5.1972e-01, 2.7000e-01, 5.2688e-05, 2.1023e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.48\n",
      "59.63925245830067\n",
      "probs: tensor([[0.1375, 0.0689, 0.5994, 0.1942]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.48\n",
      "probs: tensor([[0.1604, 0.2582, 0.5320, 0.0494]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.48\n",
      "probs: tensor([[5.8221e-01, 2.4303e-01, 2.6431e-05, 1.7473e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.48\n",
      "probs: tensor([[0.2716, 0.2141, 0.3555, 0.1587]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.47\n",
      "probs: tensor([[5.2645e-01, 2.4944e-01, 4.1581e-04, 2.2369e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.47\n",
      "probs: tensor([[6.5847e-01, 1.6330e-01, 3.1036e-05, 1.7820e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.47\n",
      "77.22887366696952\n",
      "probs: tensor([[0.0317, 0.0161, 0.7496, 0.2026]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.47\n",
      "probs: tensor([[6.1310e-01, 2.4549e-01, 6.5090e-05, 1.4135e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.47\n",
      "probs: tensor([[5.7493e-01, 2.4181e-01, 9.7515e-05, 1.8316e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.47\n",
      "probs: tensor([[6.5978e-01, 1.8672e-01, 6.7255e-06, 1.5349e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.47\n",
      "probs: tensor([[0.0687, 0.1769, 0.7123, 0.0421]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.47\n",
      "probs: tensor([[6.2014e-01, 1.8930e-01, 2.8119e-05, 1.9053e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.46\n",
      "probs: tensor([[5.8557e-01, 2.3348e-01, 5.1700e-05, 1.8090e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.46\n",
      "102.34004083673906\n",
      "probs: tensor([[0.1082, 0.1198, 0.6674, 0.1047]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.46\n",
      "probs: tensor([[5.4113e-01, 2.8240e-01, 1.6681e-04, 1.7631e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.46\n",
      "probs: tensor([[5.8948e-01, 2.7751e-01, 1.1675e-05, 1.3299e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.46\n",
      "probs: tensor([[0.3427, 0.1757, 0.2955, 0.1861]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.46\n",
      "probs: tensor([[1.6773e-01, 1.7043e-03, 3.6821e-05, 8.3053e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.46\n",
      "probs: tensor([[5.8530e-01, 2.5663e-01, 4.0645e-05, 1.5804e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.46\n",
      "probs: tensor([[6.1135e-01, 2.6371e-01, 1.6006e-05, 1.2493e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.45\n",
      "126.02029286654525\n",
      "probs: tensor([[0.0859, 0.0225, 0.7520, 0.1396]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.45\n",
      "probs: tensor([[9.7598e-01, 2.5152e-08, 6.8992e-12, 2.4023e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.45\n",
      "probs: tensor([[5.8787e-01, 2.4232e-01, 1.1772e-04, 1.6970e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.45\n",
      "probs: tensor([[0.1162, 0.0269, 0.6236, 0.2333]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.45\n",
      "probs: tensor([[0.0815, 0.1445, 0.7509, 0.0231]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.45\n",
      "probs: tensor([[5.3643e-01, 2.5123e-01, 3.9204e-04, 2.1194e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.45\n",
      "137.37374417619552\n",
      "probs: tensor([[0.2400, 0.1913, 0.4161, 0.1526]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.44\n",
      "probs: tensor([[0.1022, 0.0137, 0.6389, 0.2452]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.44\n",
      "probs: tensor([[6.0960e-01, 2.6127e-01, 2.2390e-05, 1.2911e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.44\n",
      "probs: tensor([[6.1262e-01, 2.5430e-01, 4.2528e-05, 1.3304e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.44\n",
      "probs: tensor([[0.0976, 0.0160, 0.7973, 0.0892]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.44\n",
      "probs: tensor([[4.7553e-01, 3.8410e-01, 6.8595e-05, 1.4030e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.44\n",
      "probs: tensor([[6.4769e-01, 2.3328e-01, 1.0598e-05, 1.1902e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.44\n",
      "123.52508528111301\n",
      "probs: tensor([[0.1534, 0.1024, 0.5638, 0.1805]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.44\n",
      "probs: tensor([[5.6330e-01, 2.7948e-01, 9.0637e-05, 1.5713e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.43\n",
      "probs: tensor([[5.8379e-01, 2.5670e-01, 7.0448e-05, 1.5944e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.43\n",
      "probs: tensor([[0.4579, 0.4144, 0.0011, 0.1267]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.43\n",
      "probs: tensor([[0.2759, 0.0571, 0.2911, 0.3760]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.43\n",
      "probs: tensor([[6.5290e-01, 1.9046e-01, 4.5109e-05, 1.5659e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.43\n",
      "probs: tensor([[6.1462e-01, 2.2380e-01, 1.2640e-04, 1.6146e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.43\n",
      "128.99036066114434\n",
      "probs: tensor([[0.0739, 0.0318, 0.7950, 0.0993]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.43\n",
      "probs: tensor([[5.6507e-01, 2.5920e-01, 2.2321e-04, 1.7551e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.43\n",
      "probs: tensor([[6.0726e-01, 2.2433e-01, 1.1787e-04, 1.6829e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.42\n",
      "probs: tensor([[0.0589, 0.0074, 0.7299, 0.2037]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.42\n",
      "probs: tensor([[0.3499, 0.1260, 0.0913, 0.4328]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.42\n",
      "probs: tensor([[6.7703e-01, 1.9786e-01, 1.0514e-05, 1.2509e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.42\n",
      "116.9961392491418\n",
      "probs: tensor([[4.8907e-01, 2.1900e-01, 1.6396e-05, 2.9191e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.42\n",
      "probs: tensor([[0.2393, 0.3624, 0.3320, 0.0663]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.42\n",
      "probs: tensor([[3.6063e-01, 4.0110e-02, 2.2905e-04, 5.9903e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.42\n",
      "probs: tensor([[2.9060e-01, 3.8378e-02, 4.5536e-04, 6.7057e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.42\n",
      "probs: tensor([[0.1709, 0.2458, 0.5371, 0.0463]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.41\n",
      "probs: tensor([[5.2317e-01, 2.9071e-01, 4.6797e-04, 1.8566e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.41\n",
      "probs: tensor([[6.2419e-01, 2.0792e-01, 3.5066e-05, 1.6785e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.41\n",
      "109.65085233756956\n",
      "probs: tensor([[0.1468, 0.3465, 0.4809, 0.0259]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.41\n",
      "probs: tensor([[6.1961e-01, 2.1494e-01, 1.3436e-05, 1.6544e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.41\n",
      "probs: tensor([[5.9197e-01, 2.4403e-01, 4.0484e-05, 1.6395e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.41\n",
      "probs: tensor([[5.5846e-01, 2.4922e-01, 7.9146e-05, 1.9224e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.41\n",
      "probs: tensor([[8.4442e-01, 2.4715e-06, 2.4240e-07, 1.5558e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.41\n",
      "136.10070830841363\n",
      "probs: tensor([[0.0402, 0.0241, 0.9047, 0.0310]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.4\n",
      "probs: tensor([[6.0490e-01, 2.2801e-01, 1.7893e-05, 1.6707e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.4\n",
      "probs: tensor([[6.3578e-01, 2.3140e-01, 8.3515e-06, 1.3282e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.4\n",
      "probs: tensor([[0.1957, 0.1978, 0.5047, 0.1018]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.4\n",
      "probs: tensor([[5.4971e-01, 2.8214e-01, 6.4157e-05, 1.6808e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.4\n",
      "probs: tensor([[5.7325e-01, 2.6992e-01, 1.0265e-04, 1.5673e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.4\n",
      "157.679228740554\n",
      "probs: tensor([[0.1260, 0.0491, 0.6347, 0.1903]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.4\n",
      "probs: tensor([[0.1630, 0.0944, 0.6057, 0.1368]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.4\n",
      "126.47058357895533\n",
      "probs: tensor([[0.0864, 0.0439, 0.8162, 0.0534]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.4\n",
      "probs: tensor([[3.7233e-01, 5.9592e-01, 1.3903e-05, 3.1738e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.39\n",
      "probs: tensor([[4.6796e-01, 4.1741e-01, 2.1643e-04, 1.1441e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.39\n",
      "probs: tensor([[5.6962e-01, 2.5652e-01, 1.1142e-04, 1.7375e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.39\n",
      "probs: tensor([[0.0746, 0.2357, 0.6784, 0.0112]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.39\n",
      "143.7746581643101\n",
      "probs: tensor([[0.1512, 0.1464, 0.5842, 0.1182]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.39\n",
      "probs: tensor([[6.0395e-01, 2.1514e-01, 2.3102e-05, 1.8088e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.39\n",
      "probs: tensor([[6.0002e-01, 2.4001e-01, 1.4480e-05, 1.5996e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.39\n",
      "probs: tensor([[0.0463, 0.0027, 0.7938, 0.1573]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.39\n",
      "probs: tensor([[5.6806e-01, 2.5890e-01, 6.9061e-05, 1.7297e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.39\n",
      "probs: tensor([[5.8752e-01, 2.5203e-01, 2.4789e-05, 1.6043e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.38\n",
      "probs: tensor([[5.5395e-01, 2.6666e-01, 6.1188e-05, 1.7933e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.38\n",
      "145.01292941742275\n",
      "probs: tensor([[0.0949, 0.0820, 0.7771, 0.0461]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.38\n",
      "probs: tensor([[0.1398, 0.1036, 0.5701, 0.1865]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.38\n",
      "probs: tensor([[0.3321, 0.1138, 0.2946, 0.2596]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.38\n",
      "probs: tensor([[5.7540e-01, 2.3296e-01, 3.6752e-05, 1.9160e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.38\n",
      "111.18425014766736\n",
      "probs: tensor([[0.3801, 0.4787, 0.0083, 0.1329]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.38\n",
      "probs: tensor([[0.0580, 0.0096, 0.8405, 0.0918]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.38\n",
      "probs: tensor([[6.2890e-01, 1.9048e-01, 6.5097e-06, 1.8061e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.37\n",
      "probs: tensor([[6.0396e-01, 1.7120e-01, 1.2569e-05, 2.2483e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.37\n",
      "probs: tensor([[0.2077, 0.1304, 0.5153, 0.1465]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.37\n",
      "probs: tensor([[6.6204e-01, 1.7092e-01, 3.6748e-06, 1.6703e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.37\n",
      "probs: tensor([[6.3914e-01, 1.9307e-01, 1.1627e-05, 1.6778e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.37\n",
      "97.89271153748655\n",
      "probs: tensor([[0.0337, 0.0019, 0.7345, 0.2299]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.37\n",
      "probs: tensor([[5.4833e-01, 3.8045e-01, 2.6180e-05, 7.1201e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.37\n",
      "probs: tensor([[5.7516e-01, 2.4198e-01, 1.0604e-04, 1.8276e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.37\n",
      "probs: tensor([[6.3897e-01, 2.0932e-01, 2.4647e-05, 1.5169e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.37\n",
      "probs: tensor([[0.0722, 0.0846, 0.8064, 0.0367]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.36\n",
      "probs: tensor([[6.0006e-01, 2.3528e-01, 5.2915e-05, 1.6460e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.36\n",
      "probs: tensor([[6.1351e-01, 2.2072e-01, 3.7169e-05, 1.6574e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.36\n",
      "127.41640477616133\n",
      "probs: tensor([[0.1048, 0.1434, 0.7390, 0.0129]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.36\n",
      "probs: tensor([[5.5050e-01, 3.4815e-01, 5.9488e-05, 1.0129e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.36\n",
      "probs: tensor([[5.5853e-01, 3.4076e-01, 7.7327e-05, 1.0063e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.36\n",
      "probs: tensor([[0.0816, 0.1469, 0.7438, 0.0277]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.36\n",
      "98.97828279557385\n",
      "probs: tensor([[0.2092, 0.2302, 0.5089, 0.0517]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.36\n",
      "probs: tensor([[0.0667, 0.1005, 0.8054, 0.0274]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.36\n",
      "probs: tensor([[0.0639, 0.0130, 0.7152, 0.2079]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.36\n",
      "probs: tensor([[6.3968e-01, 1.8919e-01, 9.1177e-06, 1.7112e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.35\n",
      "probs: tensor([[6.1916e-01, 1.8729e-01, 2.9172e-05, 1.9352e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.35\n",
      "109.346842382519\n",
      "probs: tensor([[0.0877, 0.0886, 0.7748, 0.0488]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.35\n",
      "probs: tensor([[8.8274e-02, 9.9976e-03, 1.0664e-07, 9.0173e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.35\n",
      "probs: tensor([[0.3102, 0.0739, 0.4557, 0.1602]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.35\n",
      "117.65434073432394\n",
      "probs: tensor([[0.3445, 0.0619, 0.3568, 0.2367]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.35\n",
      "probs: tensor([[0.1470, 0.0240, 0.6294, 0.1996]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.35\n",
      "probs: tensor([[5.9274e-01, 2.2274e-01, 3.1317e-05, 1.8449e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.35\n",
      "probs: tensor([[0.0750, 0.0976, 0.8217, 0.0057]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.35\n",
      "probs: tensor([[5.8891e-01, 2.2066e-01, 1.6045e-04, 1.9027e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.34\n",
      "probs: tensor([[5.9623e-01, 2.2159e-01, 8.9117e-05, 1.8209e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.34\n",
      "probs: tensor([[6.1184e-01, 2.0820e-01, 3.9920e-05, 1.7992e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.34\n",
      "121.86334526845792\n",
      "probs: tensor([[0.1296, 0.0244, 0.4128, 0.4332]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.34\n",
      "probs: tensor([[6.1820e-01, 1.7180e-01, 3.1359e-05, 2.0998e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.34\n",
      "probs: tensor([[6.1400e-01, 2.2581e-01, 3.0357e-05, 1.6016e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.34\n",
      "probs: tensor([[0.3215, 0.2824, 0.2502, 0.1460]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.34\n",
      "probs: tensor([[6.5078e-01, 1.7409e-01, 2.2318e-05, 1.7511e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.34\n",
      "probs: tensor([[6.9741e-01, 1.6256e-01, 4.1931e-06, 1.4002e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.34\n",
      "119.21052070597193\n",
      "probs: tensor([[0.0775, 0.0299, 0.7804, 0.1122]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.34\n",
      "probs: tensor([[0.2984, 0.1950, 0.3912, 0.1154]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.33\n",
      "probs: tensor([[6.5953e-01, 1.8415e-01, 7.8215e-06, 1.5631e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.33\n",
      "probs: tensor([[6.7747e-01, 1.8749e-01, 5.7652e-06, 1.3503e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.33\n",
      "probs: tensor([[0.1231, 0.1596, 0.6811, 0.0362]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.33\n",
      "141.76932045986808\n",
      "probs: tensor([[0.1824, 0.1962, 0.5609, 0.0605]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.33\n",
      "probs: tensor([[6.7456e-01, 1.7528e-01, 8.1235e-06, 1.5015e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.33\n",
      "probs: tensor([[7.1924e-01, 1.6124e-01, 1.3057e-06, 1.1952e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.33\n",
      "probs: tensor([[0.1227, 0.0973, 0.6884, 0.0916]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.33\n",
      "probs: tensor([[6.8233e-01, 1.8330e-01, 5.4698e-06, 1.3436e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.33\n",
      "probs: tensor([[6.4419e-01, 1.9268e-01, 2.2788e-05, 1.6311e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.33\n",
      "probs: tensor([[6.4607e-01, 2.0690e-01, 1.1963e-05, 1.4702e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.32\n",
      "136.03272955760684\n",
      "probs: tensor([[0.0398, 0.0039, 0.8427, 0.1136]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.32\n",
      "probs: tensor([[6.5247e-01, 1.7476e-01, 5.0235e-05, 1.7272e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.32\n",
      "probs: tensor([[6.4798e-01, 1.7487e-01, 2.3144e-05, 1.7713e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.32\n",
      "probs: tensor([[0.2227, 0.5726, 0.1517, 0.0530]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.32\n",
      "probs: tensor([[0.2567, 0.0434, 0.1743, 0.5256]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.32\n",
      "probs: tensor([[6.5570e-01, 1.9404e-01, 1.4038e-05, 1.5025e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.32\n",
      "145.7843670686901\n",
      "probs: tensor([[0.3019, 0.5529, 0.0271, 0.1182]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.32\n",
      "probs: tensor([[0.1186, 0.1428, 0.7139, 0.0248]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.32\n",
      "probs: tensor([[6.2966e-01, 1.5492e-01, 2.3870e-05, 2.1539e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.32\n",
      "probs: tensor([[6.6599e-01, 1.6125e-01, 6.8584e-06, 1.7276e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.32\n",
      "probs: tensor([[0.0555, 0.0885, 0.8280, 0.0280]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.31\n",
      "probs: tensor([[6.5159e-01, 2.6300e-01, 5.1502e-07, 8.5410e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.31\n",
      "probs: tensor([[6.6959e-01, 1.8712e-01, 2.8395e-06, 1.4329e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.31\n",
      "144.92302459917673\n",
      "probs: tensor([[0.3203, 0.2797, 0.2810, 0.1190]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.31\n",
      "probs: tensor([[6.7497e-01, 2.1828e-01, 3.5855e-06, 1.0675e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.31\n",
      "probs: tensor([[6.3151e-01, 1.9384e-01, 2.6319e-05, 1.7463e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.31\n",
      "probs: tensor([[2.5953e-01, 6.2862e-01, 2.8444e-06, 1.1185e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.31\n",
      "probs: tensor([[0.1161, 0.1539, 0.6922, 0.0377]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.31\n",
      "159.4453304074273\n",
      "probs: tensor([[0.0855, 0.1428, 0.7591, 0.0126]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.31\n",
      "probs: tensor([[6.4804e-01, 1.5771e-01, 2.0312e-05, 1.9422e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.31\n",
      "probs: tensor([[5.0024e-01, 9.1519e-02, 5.0630e-05, 4.0819e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.31\n",
      "probs: tensor([[0.0431, 0.0074, 0.8865, 0.0630]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.3\n",
      "probs: tensor([[0.1162, 0.0693, 0.6226, 0.1919]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.3\n",
      "probs: tensor([[7.1951e-01, 1.7212e-01, 7.4264e-07, 1.0837e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.3\n",
      "probs: tensor([[7.1539e-01, 1.9363e-01, 1.0678e-07, 9.0985e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.3\n",
      "152.90575481191962\n",
      "probs: tensor([[0.1894, 0.1087, 0.4986, 0.2033]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.3\n",
      "probs: tensor([[6.8481e-01, 1.5867e-01, 1.3586e-06, 1.5652e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.3\n",
      "probs: tensor([[7.0028e-01, 1.8382e-01, 5.6164e-07, 1.1589e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.3\n",
      "probs: tensor([[0.3576, 0.1506, 0.4201, 0.0717]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.3\n",
      "probs: tensor([[6.1881e-01, 8.3099e-02, 2.2318e-05, 2.9807e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.3\n",
      "probs: tensor([[5.2668e-01, 4.5767e-02, 1.8262e-05, 4.2754e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.3\n",
      "149.71678042972962\n",
      "probs: tensor([[0.2180, 0.5077, 0.2155, 0.0588]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.3\n",
      "probs: tensor([[0.2002, 0.3057, 0.4614, 0.0327]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.29\n",
      "probs: tensor([[6.0215e-01, 3.5515e-01, 2.8446e-08, 4.2702e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.29\n",
      "probs: tensor([[6.4802e-01, 2.9169e-01, 7.9278e-08, 6.0298e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.29\n",
      "probs: tensor([[0.1826, 0.2234, 0.5378, 0.0562]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.29\n",
      "probs: tensor([[7.3026e-01, 1.8434e-01, 1.0964e-06, 8.5404e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.29\n",
      "probs: tensor([[7.0545e-01, 1.6852e-01, 3.7958e-06, 1.2602e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.29\n",
      "147.8837217759921\n",
      "probs: tensor([[0.1029, 0.4155, 0.4661, 0.0155]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.29\n",
      "probs: tensor([[0.1089, 0.0042, 0.3901, 0.4969]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.29\n",
      "probs: tensor([[6.6855e-01, 1.8061e-01, 3.0146e-05, 1.5081e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.29\n",
      "probs: tensor([[0.0577, 0.0176, 0.8097, 0.1150]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.29\n",
      "probs: tensor([[6.8793e-01, 1.9884e-01, 6.6937e-06, 1.1322e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.29\n",
      "probs: tensor([[6.8143e-01, 1.3319e-01, 1.2034e-05, 1.8537e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.28\n",
      "probs: tensor([[6.5538e-01, 1.8612e-01, 3.2707e-05, 1.5846e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.28\n",
      "140.1142794443519\n",
      "probs: tensor([[0.1463, 0.0733, 0.5945, 0.1859]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.28\n",
      "probs: tensor([[6.7480e-01, 1.7623e-01, 1.1777e-05, 1.4896e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.28\n",
      "probs: tensor([[7.3541e-01, 1.4284e-01, 9.1760e-07, 1.2176e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.28\n",
      "probs: tensor([[0.1208, 0.0448, 0.6937, 0.1406]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.28\n",
      "probs: tensor([[6.9281e-01, 1.6678e-01, 5.2360e-06, 1.4040e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.28\n",
      "probs: tensor([[7.6117e-01, 1.3083e-01, 4.9899e-07, 1.0800e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.28\n",
      "124.38317660242163\n",
      "probs: tensor([[0.4257, 0.2397, 0.0615, 0.2731]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.28\n",
      "probs: tensor([[0.3289, 0.1220, 0.3663, 0.1828]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.28\n",
      "probs: tensor([[6.8537e-01, 1.7834e-01, 6.4953e-06, 1.3628e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.28\n",
      "probs: tensor([[6.5807e-01, 1.4646e-01, 1.2064e-05, 1.9546e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.28\n",
      "probs: tensor([[0.1040, 0.0601, 0.7651, 0.0709]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.27\n",
      "probs: tensor([[6.8045e-01, 1.6350e-01, 2.6832e-05, 1.5602e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.27\n",
      "probs: tensor([[6.8866e-01, 1.6387e-01, 1.8329e-05, 1.4746e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.27\n",
      "125.62097835595898\n",
      "probs: tensor([[0.2364, 0.2658, 0.4424, 0.0554]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.27\n",
      "probs: tensor([[6.7286e-01, 1.6929e-01, 7.7589e-06, 1.5784e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.27\n",
      "probs: tensor([[7.2761e-01, 1.2546e-01, 2.0090e-06, 1.4693e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.27\n",
      "probs: tensor([[0.3349, 0.3346, 0.1501, 0.1805]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.27\n",
      "probs: tensor([[0.2152, 0.1232, 0.6201, 0.0415]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.27\n",
      "probs: tensor([[6.5766e-01, 1.1873e-01, 1.4891e-05, 2.2360e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.27\n",
      "130.56917548566156\n",
      "probs: tensor([[0.2590, 0.0610, 0.4087, 0.2713]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.27\n",
      "probs: tensor([[6.9893e-01, 1.5806e-01, 7.9936e-06, 1.4300e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.27\n",
      "probs: tensor([[6.6215e-01, 1.7935e-01, 1.6402e-05, 1.5848e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.27\n",
      "probs: tensor([[0.0406, 0.0064, 0.8838, 0.0692]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.27\n",
      "probs: tensor([[6.8389e-01, 1.4767e-01, 8.4851e-06, 1.6842e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.26\n",
      "probs: tensor([[7.0225e-01, 1.2530e-01, 3.9812e-06, 1.7245e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.26\n",
      "probs: tensor([[6.9987e-01, 1.2119e-01, 3.7189e-06, 1.7894e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.26\n",
      "143.107644950253\n",
      "probs: tensor([[0.0794, 0.1376, 0.7532, 0.0298]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.26\n",
      "probs: tensor([[7.3633e-01, 1.1969e-01, 1.3245e-06, 1.4398e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.26\n",
      "probs: tensor([[7.2469e-01, 1.5086e-01, 1.9855e-06, 1.2444e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.26\n",
      "probs: tensor([[0.1563, 0.0342, 0.6457, 0.1638]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.26\n",
      "probs: tensor([[6.6895e-01, 1.6698e-01, 1.2693e-05, 1.6407e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.26\n",
      "probs: tensor([[6.3456e-01, 1.7570e-01, 8.0420e-05, 1.8967e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.26\n",
      "150.41972579893778\n",
      "probs: tensor([[0.0339, 0.0084, 0.6626, 0.2951]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.26\n",
      "probs: tensor([[6.6959e-01, 1.6067e-01, 1.0046e-05, 1.6973e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.26\n",
      "probs: tensor([[6.5372e-01, 1.8835e-01, 1.6649e-05, 1.5791e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.26\n",
      "probs: tensor([[6.7867e-01, 1.2680e-01, 1.4060e-05, 1.9452e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.26\n",
      "probs: tensor([[0.1092, 0.2591, 0.6233, 0.0084]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.25\n",
      "probs: tensor([[6.7951e-01, 1.3894e-01, 1.6616e-05, 1.8153e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.25\n",
      "164.08273510551032\n",
      "probs: tensor([[0.1672, 0.1180, 0.6047, 0.1101]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.25\n",
      "probs: tensor([[6.7184e-01, 1.7180e-01, 2.1419e-05, 1.5634e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.25\n",
      "probs: tensor([[7.0257e-01, 1.7030e-01, 5.8156e-06, 1.2713e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.25\n",
      "probs: tensor([[0.1967, 0.1155, 0.5256, 0.1621]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.25\n",
      "probs: tensor([[6.5192e-01, 2.1494e-01, 6.6461e-06, 1.3313e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.25\n",
      "probs: tensor([[6.7401e-01, 1.5438e-01, 7.8313e-06, 1.7160e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.25\n",
      "166.03154040156\n",
      "probs: tensor([[0.0180, 0.0845, 0.8863, 0.0112]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.25\n",
      "probs: tensor([[6.3996e-01, 2.1702e-01, 6.3943e-06, 1.4301e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.25\n",
      "probs: tensor([[5.9091e-01, 3.4248e-01, 6.6760e-06, 6.6608e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.25\n",
      "probs: tensor([[5.4068e-01, 3.9844e-01, 9.0269e-06, 6.0864e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.25\n",
      "probs: tensor([[0.1877, 0.3373, 0.4457, 0.0292]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.25\n",
      "probs: tensor([[6.9954e-01, 1.4181e-01, 3.8388e-06, 1.5864e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.24\n",
      "probs: tensor([[7.3595e-01, 1.1015e-01, 1.1102e-06, 1.5391e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.24\n",
      "162.36321411539745\n",
      "probs: tensor([[0.1219, 0.0609, 0.7968, 0.0203]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.24\n",
      "probs: tensor([[6.8393e-01, 1.3237e-01, 7.4027e-06, 1.8369e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.24\n",
      "probs: tensor([[6.4373e-01, 1.1932e-01, 8.9639e-06, 2.3694e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.24\n",
      "probs: tensor([[0.1768, 0.0244, 0.5431, 0.2557]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.24\n",
      "probs: tensor([[2.1302e-01, 2.2194e-03, 2.8303e-06, 7.8476e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.24\n",
      "probs: tensor([[2.6981e-01, 4.8669e-03, 7.7437e-06, 7.2531e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.24\n",
      "probs: tensor([[3.2327e-01, 6.6365e-03, 6.2603e-06, 6.7009e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.24\n",
      "147.8536897600304\n",
      "probs: tensor([[0.1463, 0.6808, 0.1596, 0.0133]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.24\n",
      "probs: tensor([[7.1456e-01, 1.1289e-01, 4.5536e-06, 1.7254e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.24\n",
      "probs: tensor([[6.4827e-01, 2.3179e-01, 2.3690e-05, 1.1992e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.24\n",
      "probs: tensor([[0.2280, 0.2278, 0.5170, 0.0272]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.24\n",
      "probs: tensor([[6.7059e-01, 1.8808e-01, 9.1892e-06, 1.4132e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.24\n",
      "probs: tensor([[6.7917e-01, 1.9412e-01, 4.8700e-06, 1.2670e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.23\n",
      "142.85121680141125\n",
      "probs: tensor([[0.0836, 0.0123, 0.7981, 0.1060]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.23\n",
      "probs: tensor([[6.9140e-01, 1.9197e-01, 3.7818e-06, 1.1662e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.23\n",
      "probs: tensor([[7.0755e-01, 1.4733e-01, 4.7266e-06, 1.4511e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.23\n",
      "probs: tensor([[7.0153e-01, 1.5342e-01, 6.4113e-06, 1.4504e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.23\n",
      "probs: tensor([[0.0398, 0.0466, 0.8993, 0.0144]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.23\n",
      "probs: tensor([[7.1279e-01, 1.0804e-01, 7.0003e-06, 1.7917e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.23\n",
      "139.29182555958306\n",
      "probs: tensor([[0.1282, 0.2631, 0.5851, 0.0236]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.23\n",
      "probs: tensor([[1.0237e-01, 4.4918e-04, 2.4694e-06, 8.9717e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.23\n",
      "probs: tensor([[2.5650e-01, 2.7708e-03, 2.3350e-06, 7.4073e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.23\n",
      "probs: tensor([[0.2878, 0.1206, 0.2569, 0.3347]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.23\n",
      "probs: tensor([[0.1119, 0.0445, 0.7604, 0.0832]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.23\n",
      "141.9405502430304\n",
      "probs: tensor([[0.3363, 0.2679, 0.2723, 0.1235]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.23\n",
      "probs: tensor([[0.2107, 0.0427, 0.4752, 0.2714]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.23\n",
      "probs: tensor([[7.7688e-01, 1.3989e-01, 3.8624e-07, 8.3226e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.23\n",
      "probs: tensor([[7.9344e-01, 1.3382e-01, 2.6104e-07, 7.2748e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.22\n",
      "probs: tensor([[8.1384e-01, 1.4914e-01, 1.0630e-08, 3.7024e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.22\n",
      "122.70381448541532\n",
      "probs: tensor([[0.3688, 0.1041, 0.4894, 0.0377]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.22\n",
      "probs: tensor([[6.8354e-01, 1.7378e-01, 1.1703e-05, 1.4266e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.22\n",
      "probs: tensor([[6.8951e-01, 1.3750e-01, 4.5437e-06, 1.7299e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.22\n",
      "probs: tensor([[0.0464, 0.0147, 0.8331, 0.1059]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.22\n",
      "probs: tensor([[1.5234e-01, 1.5102e-03, 7.5358e-06, 8.4614e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.22\n",
      "probs: tensor([[2.3725e-01, 2.7726e-03, 1.1617e-05, 7.5997e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.22\n",
      "125.45940547464185\n",
      "probs: tensor([[0.1597, 0.1000, 0.1466, 0.5937]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.22\n",
      "probs: tensor([[6.5798e-01, 3.3941e-01, 6.1831e-11, 2.6045e-03]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.22\n",
      "probs: tensor([[4.9766e-01, 4.9933e-01, 2.2636e-09, 3.0069e-03]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.22\n",
      "probs: tensor([[1.7111e-01, 8.2821e-01, 9.4470e-10, 6.8247e-04]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.22\n",
      "probs: tensor([[0.1724, 0.4685, 0.2734, 0.0857]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.22\n",
      "138.59016593265733\n",
      "probs: tensor([[0.2968, 0.4453, 0.2242, 0.0337]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.22\n",
      "probs: tensor([[0.2032, 0.2398, 0.2307, 0.3263]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.22\n",
      "probs: tensor([[0.1190, 0.1005, 0.7336, 0.0469]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.21\n",
      "probs: tensor([[0.1168, 0.2573, 0.6138, 0.0121]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.21\n",
      "probs: tensor([[7.4779e-01, 1.3011e-01, 3.0193e-06, 1.2210e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.21\n",
      "probs: tensor([[7.3196e-01, 1.2769e-01, 3.9441e-06, 1.4034e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.21\n",
      "131.0497955705754\n",
      "probs: tensor([[0.3045, 0.0466, 0.6097, 0.0392]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.21\n",
      "probs: tensor([[6.4857e-01, 4.5468e-02, 2.3906e-06, 3.0596e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.21\n",
      "probs: tensor([[7.3804e-01, 5.7516e-02, 1.9903e-06, 2.0445e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.21\n",
      "probs: tensor([[0.2103, 0.1329, 0.6319, 0.0248]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.21\n",
      "130.93425509877142\n",
      "probs: tensor([[0.0693, 0.0269, 0.8265, 0.0773]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.21\n",
      "probs: tensor([[7.6157e-01, 8.1043e-02, 1.5393e-06, 1.5738e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.21\n",
      "probs: tensor([[7.3104e-01, 7.8623e-02, 3.3268e-06, 1.9033e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.21\n",
      "probs: tensor([[7.5210e-01, 6.9973e-02, 2.4990e-06, 1.7793e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.21\n",
      "probs: tensor([[0.2857, 0.2636, 0.3374, 0.1133]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.21\n",
      "probs: tensor([[7.5758e-01, 1.0209e-01, 1.9131e-06, 1.4033e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.21\n",
      "probs: tensor([[7.8449e-01, 9.1299e-02, 8.5892e-07, 1.2421e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.21\n",
      "149.81651065625377\n",
      "probs: tensor([[0.2156, 0.1546, 0.5832, 0.0466]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.21\n",
      "probs: tensor([[6.1591e-01, 3.5853e-01, 6.3790e-07, 2.5555e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.2\n",
      "probs: tensor([[7.4246e-01, 2.2425e-01, 2.6654e-07, 3.3294e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.2\n",
      "probs: tensor([[0.2198, 0.1499, 0.5158, 0.1144]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.2\n",
      "probs: tensor([[7.2562e-01, 1.2138e-01, 4.6001e-06, 1.5300e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.2\n",
      "probs: tensor([[7.5177e-01, 9.4585e-02, 2.0259e-06, 1.5364e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.2\n",
      "probs: tensor([[7.2490e-01, 1.4823e-01, 3.0887e-06, 1.2687e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.2\n",
      "151.71800239477307\n",
      "probs: tensor([[0.4620, 0.1942, 0.2320, 0.1118]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.2\n",
      "probs: tensor([[7.6713e-01, 1.0444e-01, 1.7780e-06, 1.2843e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.2\n",
      "probs: tensor([[7.3620e-01, 7.7911e-02, 2.5965e-06, 1.8589e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.2\n",
      "probs: tensor([[0.0510, 0.3987, 0.5480, 0.0023]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.2\n",
      "probs: tensor([[3.8749e-01, 6.0923e-01, 1.1723e-07, 3.2831e-03]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.2\n",
      "probs: tensor([[4.0062e-01, 5.9660e-01, 2.1833e-07, 2.7837e-03]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.2\n",
      "138.73737490232418\n",
      "probs: tensor([[0.0609, 0.0727, 0.8522, 0.0142]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.2\n",
      "probs: tensor([[0.0903, 0.1036, 0.7517, 0.0544]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.2\n",
      "probs: tensor([[7.0692e-01, 6.6849e-02, 8.0607e-06, 2.2623e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.2\n",
      "probs: tensor([[7.9255e-01, 5.7976e-02, 1.2051e-06, 1.4947e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.2\n",
      "probs: tensor([[0.2537, 0.2572, 0.4594, 0.0297]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.19\n",
      "probs: tensor([[2.8982e-01, 7.0913e-01, 3.2004e-08, 1.0500e-03]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.19\n",
      "probs: tensor([[2.1667e-01, 7.8296e-01, 3.2326e-08, 3.6833e-04]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.19\n",
      "137.38768851944005\n",
      "probs: tensor([[0.1494, 0.0857, 0.7306, 0.0344]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.19\n",
      "probs: tensor([[8.2123e-01, 1.1575e-01, 4.1109e-07, 6.3023e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.19\n",
      "probs: tensor([[0.1605, 0.1870, 0.6043, 0.0482]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.19\n",
      "probs: tensor([[2.7213e-01, 7.2618e-01, 2.3330e-09, 1.6857e-03]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.19\n",
      "probs: tensor([[5.7010e-01, 4.2628e-01, 1.3401e-09, 3.6142e-03]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.19\n",
      "137.10630895006793\n",
      "probs: tensor([[0.1509, 0.0668, 0.7095, 0.0728]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.19\n",
      "probs: tensor([[7.9890e-01, 1.4050e-01, 4.4652e-07, 6.0602e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.19\n",
      "probs: tensor([[8.0080e-01, 1.3073e-01, 7.0930e-07, 6.8469e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.19\n",
      "probs: tensor([[0.2465, 0.0627, 0.6525, 0.0383]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.19\n",
      "probs: tensor([[5.1880e-01, 1.8451e-02, 9.8714e-06, 4.6273e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.19\n",
      "probs: tensor([[3.0309e-01, 6.3876e-03, 1.8984e-05, 6.9051e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.19\n",
      "probs: tensor([[4.9392e-01, 1.4778e-02, 1.2751e-05, 4.9129e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.19\n",
      "138.44773921724638\n",
      "probs: tensor([[0.2232, 0.3166, 0.4412, 0.0190]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.19\n",
      "probs: tensor([[3.3484e-01, 7.0885e-03, 7.4527e-06, 6.5806e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.19\n",
      "probs: tensor([[2.6289e-01, 7.3823e-03, 1.9028e-05, 7.2971e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.19\n",
      "probs: tensor([[0.2835, 0.0808, 0.3949, 0.2407]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.18\n",
      "probs: tensor([[7.6923e-01, 8.0075e-02, 3.4349e-06, 1.5069e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.18\n",
      "probs: tensor([[7.7433e-01, 7.6267e-02, 2.6973e-06, 1.4940e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.18\n",
      "140.15722701201906\n",
      "probs: tensor([[0.1297, 0.6447, 0.2127, 0.0129]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.18\n",
      "probs: tensor([[4.3711e-02, 1.7224e-04, 9.5150e-07, 9.5612e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.18\n",
      "probs: tensor([[1.9239e-01, 1.8710e-03, 1.2369e-05, 8.0573e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.18\n",
      "probs: tensor([[1.6958e-01, 1.6194e-03, 1.4801e-05, 8.2879e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.18\n",
      "probs: tensor([[0.2094, 0.2693, 0.4857, 0.0357]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.18\n",
      "probs: tensor([[8.0128e-01, 6.4795e-02, 7.7767e-07, 1.3392e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.18\n",
      "probs: tensor([[7.9820e-01, 7.2101e-02, 1.0838e-06, 1.2970e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.18\n",
      "144.58077482689112\n",
      "probs: tensor([[0.1155, 0.0605, 0.6993, 0.1246]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.18\n",
      "probs: tensor([[7.6973e-01, 1.2037e-01, 7.6867e-07, 1.0990e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.18\n",
      "probs: tensor([[7.5156e-01, 1.5620e-01, 9.0347e-07, 9.2240e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.18\n",
      "probs: tensor([[2.7018e-01, 5.2246e-01, 4.7390e-10, 2.0736e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.18\n",
      "probs: tensor([[6.0569e-02, 3.1796e-03, 3.5729e-05, 9.3622e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.18\n",
      "163.49110051409522\n",
      "probs: tensor([[0.0875, 0.0680, 0.7894, 0.0550]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.18\n",
      "probs: tensor([[8.0237e-01, 8.8825e-02, 7.8343e-07, 1.0880e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.18\n",
      "probs: tensor([[7.9132e-01, 9.2864e-02, 9.6840e-07, 1.1582e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.18\n",
      "probs: tensor([[0.1858, 0.0651, 0.7125, 0.0367]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.18\n",
      "probs: tensor([[7.5963e-01, 6.4083e-02, 1.6264e-06, 1.7628e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.17\n",
      "probs: tensor([[7.6750e-01, 7.4824e-02, 1.6123e-06, 1.5767e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.17\n",
      "probs: tensor([[7.8073e-01, 7.5169e-02, 8.6906e-07, 1.4410e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.17\n",
      "161.77753605949613\n",
      "probs: tensor([[0.3140, 0.4321, 0.1819, 0.0720]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.17\n",
      "probs: tensor([[8.0775e-01, 6.5978e-02, 5.4976e-07, 1.2627e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.17\n",
      "probs: tensor([[8.0761e-01, 7.4806e-02, 3.8411e-07, 1.1758e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.17\n",
      "probs: tensor([[0.2045, 0.5504, 0.2192, 0.0258]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.17\n",
      "probs: tensor([[8.4127e-01, 7.7531e-02, 5.6852e-08, 8.1198e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.17\n",
      "probs: tensor([[8.2810e-01, 8.5504e-02, 9.1495e-08, 8.6395e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.17\n",
      "163.33291562529018\n",
      "probs: tensor([[0.1600, 0.0860, 0.7385, 0.0155]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.17\n",
      "probs: tensor([[7.7604e-01, 5.5391e-02, 1.6836e-06, 1.6857e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.17\n",
      "probs: tensor([[8.0636e-01, 4.1072e-02, 4.3110e-07, 1.5257e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.17\n",
      "probs: tensor([[7.9764e-01, 4.7211e-02, 3.9666e-07, 1.5515e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.17\n",
      "probs: tensor([[0.3178, 0.0653, 0.4903, 0.1265]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.17\n",
      "probs: tensor([[7.7283e-01, 4.6788e-02, 3.4892e-07, 1.8038e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.17\n",
      "probs: tensor([[8.1900e-01, 4.8087e-02, 2.5631e-07, 1.3292e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.17\n",
      "165.894949622958\n",
      "probs: tensor([[0.2010, 0.0235, 0.4433, 0.3323]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.17\n",
      "probs: tensor([[8.3994e-01, 8.2414e-02, 3.2464e-08, 7.7647e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.17\n",
      "probs: tensor([[8.1697e-01, 8.7346e-02, 8.7671e-08, 9.5681e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.17\n",
      "probs: tensor([[0.1931, 0.1229, 0.6373, 0.0466]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.16\n",
      "probs: tensor([[8.3706e-01, 4.7560e-02, 1.5043e-07, 1.1538e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.16\n",
      "probs: tensor([[8.2055e-01, 5.6865e-02, 4.2747e-07, 1.2258e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.16\n",
      "188.19412606124163\n",
      "probs: tensor([[0.1885, 0.4774, 0.3149, 0.0192]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.16\n",
      "probs: tensor([[8.0686e-01, 7.2431e-02, 3.6601e-07, 1.2071e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.16\n",
      "probs: tensor([[8.3854e-01, 4.4456e-02, 1.1496e-07, 1.1701e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.16\n",
      "probs: tensor([[0.3489, 0.2185, 0.1617, 0.2709]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.16\n",
      "probs: tensor([[6.1566e-01, 1.2542e-02, 5.0992e-07, 3.7180e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.16\n",
      "probs: tensor([[7.5265e-01, 3.0650e-02, 1.1176e-06, 2.1670e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.16\n",
      "180.77777172853948\n",
      "probs: tensor([[0.1402, 0.3318, 0.5191, 0.0090]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.16\n",
      "probs: tensor([[8.3249e-01, 8.1471e-02, 1.5606e-07, 8.6042e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.16\n",
      "probs: tensor([[8.2115e-01, 5.1599e-02, 3.2283e-07, 1.2725e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.16\n",
      "probs: tensor([[8.1596e-01, 6.4192e-02, 4.7232e-07, 1.1985e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.16\n",
      "probs: tensor([[1.1961e-01, 2.7324e-03, 1.7453e-05, 8.7764e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.16\n",
      "184.30329794328728\n",
      "probs: tensor([[0.4469, 0.1566, 0.2508, 0.1457]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.16\n",
      "probs: tensor([[9.0554e-01, 5.4387e-02, 2.1906e-09, 4.0078e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.16\n",
      "probs: tensor([[7.9464e-01, 1.0783e-01, 1.5279e-07, 9.7529e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.16\n",
      "202.4806633328293\n",
      "probs: tensor([[0.3092, 0.3306, 0.2829, 0.0773]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.16\n",
      "probs: tensor([[8.3434e-01, 5.7486e-02, 2.9052e-07, 1.0817e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.16\n",
      "probs: tensor([[8.1405e-01, 4.3792e-02, 2.9086e-07, 1.4216e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.16\n",
      "probs: tensor([[0.1151, 0.0478, 0.7035, 0.1336]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.16\n",
      "probs: tensor([[8.4519e-01, 7.9126e-02, 8.7427e-08, 7.5689e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.15\n",
      "222.42312857677743\n",
      "probs: tensor([[0.3481, 0.0291, 0.3088, 0.3140]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.15\n",
      "probs: tensor([[0.0695, 0.0010, 0.2787, 0.6508]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.15\n",
      "probs: tensor([[6.1605e-01, 1.2529e-02, 7.7317e-07, 3.7142e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.15\n",
      "probs: tensor([[7.0293e-01, 1.8087e-02, 4.6279e-07, 2.7898e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.15\n",
      "probs: tensor([[6.0482e-01, 1.3212e-02, 1.0922e-06, 3.8197e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.15\n",
      "214.37451609150685\n",
      "probs: tensor([[0.1505, 0.0983, 0.6964, 0.0548]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.15\n",
      "probs: tensor([[8.4925e-01, 6.3648e-02, 4.4403e-08, 8.7098e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.15\n",
      "probs: tensor([[8.8572e-01, 4.4191e-02, 7.5930e-09, 7.0087e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.15\n",
      "probs: tensor([[0.2850, 0.0575, 0.5395, 0.1180]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.15\n",
      "probs: tensor([[7.9002e-01, 3.9442e-02, 4.3826e-07, 1.7053e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.15\n",
      "probs: tensor([[8.0930e-01, 3.9530e-02, 4.2324e-07, 1.5117e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.15\n",
      "226.507526674386\n",
      "probs: tensor([[6.7719e-01, 1.3517e-01, 1.1672e-07, 1.8764e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.15\n",
      "probs: tensor([[8.7261e-01, 5.9482e-02, 2.4226e-08, 6.7913e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.15\n",
      "probs: tensor([[0.1335, 0.0951, 0.7328, 0.0386]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.15\n",
      "242.75737490243264\n",
      "probs: tensor([[0.2513, 0.0492, 0.6279, 0.0715]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.15\n",
      "probs: tensor([[7.3996e-01, 1.7568e-02, 5.2700e-07, 2.4247e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.15\n",
      "probs: tensor([[7.0715e-01, 1.5708e-02, 3.3178e-07, 2.7715e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.15\n",
      "probs: tensor([[7.8799e-01, 4.1223e-02, 8.6193e-07, 1.7079e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.15\n",
      "probs: tensor([[8.5191e-01, 4.8902e-02, 6.3323e-08, 9.9190e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.15\n",
      "probs: tensor([[8.5069e-01, 5.6019e-02, 5.9473e-08, 9.3292e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.15\n",
      "probs: tensor([[8.5079e-01, 5.8012e-02, 9.4519e-08, 9.1197e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.15\n",
      "231.2591707287549\n",
      "probs: tensor([[0.1355, 0.6083, 0.1978, 0.0584]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.14\n",
      "probs: tensor([[0.0101, 0.0031, 0.8668, 0.1201]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.14\n",
      "probs: tensor([[4.1851e-01, 4.4472e-03, 5.4067e-07, 5.7704e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.14\n",
      "probs: tensor([[3.7453e-01, 3.4471e-03, 1.0125e-06, 6.2202e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.14\n",
      "219.92854646221116\n",
      "probs: tensor([[0.3542, 0.0887, 0.2229, 0.3342]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.14\n",
      "probs: tensor([[8.6106e-01, 2.8203e-02, 3.9435e-08, 1.1074e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.14\n",
      "probs: tensor([[0.1366, 0.2804, 0.5460, 0.0371]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.14\n",
      "probs: tensor([[7.5890e-01, 2.4808e-02, 7.7546e-07, 2.1629e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.14\n",
      "probs: tensor([[7.3433e-01, 1.1770e-02, 1.8158e-07, 2.5390e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.14\n",
      "216.82878125654278\n",
      "probs: tensor([[0.2804, 0.1044, 0.4417, 0.1734]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.14\n",
      "probs: tensor([[8.9656e-01, 4.6639e-02, 1.2380e-09, 5.6803e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.14\n",
      "probs: tensor([[7.7171e-01, 2.0558e-01, 2.1379e-09, 2.2719e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.14\n",
      "probs: tensor([[0.0977, 0.1934, 0.7028, 0.0061]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.14\n",
      "probs: tensor([[8.4738e-01, 4.1239e-02, 1.4390e-07, 1.1138e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.14\n",
      "probs: tensor([[8.9053e-01, 6.0450e-02, 1.2709e-08, 4.9016e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.14\n",
      "200.5833577236312\n",
      "probs: tensor([[4.7177e-01, 9.0636e-02, 2.1819e-07, 4.3759e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.14\n",
      "probs: tensor([[0.1393, 0.0667, 0.7743, 0.0197]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.14\n",
      "probs: tensor([[0.0275, 0.0032, 0.9045, 0.0648]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.14\n",
      "probs: tensor([[9.2729e-01, 4.6594e-02, 4.4707e-11, 2.6112e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.14\n",
      "201.69529566301844\n",
      "probs: tensor([[0.0661, 0.0055, 0.8962, 0.0322]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.14\n",
      "probs: tensor([[8.4865e-01, 6.2357e-02, 1.0943e-07, 8.8988e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.14\n",
      "probs: tensor([[8.6719e-01, 3.6397e-02, 2.9077e-08, 9.6414e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.14\n",
      "probs: tensor([[0.2566, 0.0443, 0.5339, 0.1652]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.14\n",
      "209.3485191929846\n",
      "probs: tensor([[0.1057, 0.0052, 0.7384, 0.1508]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.14\n",
      "probs: tensor([[5.3793e-01, 1.3724e-02, 4.6146e-06, 4.4835e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.13\n",
      "probs: tensor([[0.1042, 0.2007, 0.6873, 0.0077]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.13\n",
      "212.27264365141747\n",
      "probs: tensor([[0.1110, 0.0216, 0.7779, 0.0894]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.13\n",
      "probs: tensor([[0.3469, 0.0858, 0.3600, 0.2073]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.13\n",
      "probs: tensor([[8.6213e-01, 8.1748e-02, 4.7267e-08, 5.6125e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.13\n",
      "probs: tensor([[8.4470e-01, 8.6625e-02, 1.1755e-07, 6.8671e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.13\n",
      "probs: tensor([[0.4341, 0.1030, 0.4066, 0.0563]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.13\n",
      "probs: tensor([[6.7124e-01, 1.1853e-02, 7.0213e-07, 3.1691e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.13\n",
      "probs: tensor([[6.5381e-01, 9.9705e-03, 3.8247e-07, 3.3622e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.13\n",
      "197.29319397262373\n",
      "probs: tensor([[0.0687, 0.0223, 0.8642, 0.0448]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.13\n",
      "probs: tensor([[0.1909, 0.1091, 0.6614, 0.0387]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.13\n",
      "probs: tensor([[4.0442e-01, 5.3114e-03, 1.4282e-06, 5.9027e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.13\n",
      "probs: tensor([[4.8019e-01, 6.1166e-03, 1.1108e-06, 5.1369e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.13\n",
      "204.16982386566255\n",
      "probs: tensor([[0.2602, 0.6713, 0.0309, 0.0375]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.13\n",
      "probs: tensor([[0.0056, 0.0017, 0.9848, 0.0080]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.13\n",
      "probs: tensor([[0.0661, 0.0118, 0.8510, 0.0710]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.13\n",
      "probs: tensor([[9.1002e-01, 4.4177e-02, 9.5678e-10, 4.5804e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.13\n",
      "203.96839217764008\n",
      "probs: tensor([[0.2324, 0.0886, 0.4624, 0.2166]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.13\n",
      "probs: tensor([[8.1654e-01, 5.2725e-03, 2.3815e-10, 1.7818e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.13\n",
      "probs: tensor([[6.3714e-01, 6.6873e-03, 9.5626e-09, 3.5618e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.13\n",
      "probs: tensor([[0.4423, 0.0671, 0.2207, 0.2700]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.13\n",
      "probs: tensor([[8.5791e-01, 3.6973e-02, 6.2756e-08, 1.0512e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.13\n",
      "probs: tensor([[8.7308e-01, 3.5294e-02, 2.9951e-08, 9.1623e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.13\n",
      "189.44147987252956\n",
      "probs: tensor([[0.3743, 0.0875, 0.4596, 0.0786]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.13\n",
      "probs: tensor([[8.8931e-01, 4.2135e-02, 2.3285e-08, 6.8559e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.13\n",
      "probs: tensor([[0.3399, 0.2190, 0.2863, 0.1548]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.12\n",
      "probs: tensor([[6.2057e-01, 1.1422e-02, 2.3919e-06, 3.6800e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.12\n",
      "192.83642665409292\n",
      "probs: tensor([[0.3429, 0.0150, 0.0509, 0.5912]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.12\n",
      "probs: tensor([[8.2165e-01, 1.8794e-02, 1.7394e-07, 1.5955e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.12\n",
      "probs: tensor([[8.5701e-01, 2.7500e-02, 1.3112e-07, 1.1549e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.12\n",
      "probs: tensor([[0.4305, 0.5387, 0.0007, 0.0301]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.12\n",
      "probs: tensor([[8.7310e-01, 3.0210e-02, 6.9601e-08, 9.6693e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.12\n",
      "probs: tensor([[8.6761e-01, 2.9980e-02, 6.8572e-08, 1.0241e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.12\n",
      "probs: tensor([[8.8590e-01, 3.2457e-02, 2.6628e-08, 8.1647e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.12\n",
      "195.97617171980013\n",
      "probs: tensor([[0.3286, 0.0188, 0.4660, 0.1867]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.12\n",
      "probs: tensor([[3.3891e-01, 2.4509e-01, 4.8696e-07, 4.1600e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.12\n",
      "probs: tensor([[0.0685, 0.1440, 0.7827, 0.0048]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.12\n",
      "probs: tensor([[1.1129e-01, 3.3420e-04, 7.4700e-07, 8.8837e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.12\n",
      "199.82240252391142\n",
      "probs: tensor([[0.1971, 0.0896, 0.6826, 0.0307]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.12\n",
      "probs: tensor([[0.3544, 0.0458, 0.4732, 0.1265]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.12\n",
      "198.99591426736865\n",
      "probs: tensor([[0.3031, 0.0262, 0.3923, 0.2784]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.12\n",
      "probs: tensor([[0.4663, 0.2623, 0.0048, 0.2667]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.12\n",
      "probs: tensor([[8.9641e-01, 2.3663e-02, 7.0285e-09, 7.9930e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.12\n",
      "209.31198726761704\n",
      "probs: tensor([[0.1586, 0.0958, 0.7341, 0.0115]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.12\n",
      "probs: tensor([[0.1201, 0.0016, 0.0444, 0.8339]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.12\n",
      "probs: tensor([[8.9935e-01, 2.7963e-02, 1.3589e-08, 7.2687e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.12\n",
      "probs: tensor([[9.0327e-01, 2.4490e-02, 4.3208e-09, 7.2244e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.12\n",
      "217.16403070390356\n",
      "probs: tensor([[0.0996, 0.0131, 0.4171, 0.4702]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.12\n",
      "probs: tensor([[8.7619e-01, 2.4599e-02, 1.8969e-08, 9.9214e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.12\n",
      "probs: tensor([[0.1446, 0.3947, 0.4503, 0.0104]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.12\n",
      "240.71407161547046\n",
      "probs: tensor([[0.1480, 0.2118, 0.6187, 0.0214]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.12\n",
      "probs: tensor([[0.1376, 0.0946, 0.7352, 0.0327]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.12\n",
      "probs: tensor([[9.0222e-01, 2.8279e-02, 7.7762e-09, 6.9502e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.12\n",
      "244.15747120343818\n",
      "probs: tensor([[6.7009e-02, 3.4281e-04, 3.0032e-01, 6.3233e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.11\n",
      "probs: tensor([[0.2283, 0.1805, 0.4458, 0.1454]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.11\n",
      "probs: tensor([[3.8768e-01, 9.6715e-04, 1.6852e-09, 6.1135e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.11\n",
      "probs: tensor([[1.6767e-01, 6.2543e-04, 1.2228e-08, 8.3171e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.11\n",
      "231.21505509433987\n",
      "probs: tensor([[0.2211, 0.0307, 0.5988, 0.1494]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.11\n",
      "probs: tensor([[0.4868, 0.1269, 0.0009, 0.3855]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.11\n",
      "probs: tensor([[2.9883e-01, 7.0028e-01, 4.5769e-10, 8.9285e-04]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.11\n",
      "235.56647347461185\n",
      "probs: tensor([[0.1246, 0.0668, 0.7919, 0.0167]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.11\n",
      "probs: tensor([[0.0822, 0.0465, 0.8610, 0.0102]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.11\n",
      "231.0589951493249\n",
      "probs: tensor([[0.3309, 0.0241, 0.6191, 0.0260]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.11\n",
      "probs: tensor([[6.5619e-01, 3.4339e-01, 1.7749e-14, 4.1850e-04]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.11\n",
      "probs: tensor([[4.1745e-01, 5.8244e-01, 2.5453e-15, 1.0705e-04]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.11\n",
      "probs: tensor([[9.5574e-03, 9.3329e-05, 7.8678e-04, 9.8956e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.11\n",
      "probs: tensor([[0.1230, 0.0198, 0.4569, 0.4003]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.11\n",
      "223.25644812173368\n",
      "probs: tensor([[0.0689, 0.0185, 0.8800, 0.0326]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.11\n",
      "probs: tensor([[0.1511, 0.0265, 0.7814, 0.0410]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.11\n",
      "probs: tensor([[8.9933e-01, 4.9335e-02, 1.4472e-09, 5.1334e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.11\n",
      "222.02068418191783\n",
      "probs: tensor([[0.2531, 0.1899, 0.5280, 0.0290]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.11\n",
      "probs: tensor([[0.1372, 0.0643, 0.7751, 0.0234]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.11\n",
      "227.52995603443\n",
      "probs: tensor([[0.1329, 0.0095, 0.5639, 0.2937]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.11\n",
      "probs: tensor([[9.3492e-01, 3.6915e-02, 1.2337e-10, 2.8170e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.11\n",
      "probs: tensor([[1.0045e-02, 1.3982e-03, 9.8813e-01, 4.2425e-04]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.11\n",
      "229.253502035573\n",
      "probs: tensor([[0.3935, 0.0768, 0.2671, 0.2626]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.11\n",
      "probs: tensor([[8.8923e-01, 2.3107e-02, 1.3429e-08, 8.7661e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.11\n",
      "probs: tensor([[0.3428, 0.4667, 0.0932, 0.0973]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.11\n",
      "probs: tensor([[8.3449e-01, 1.3455e-02, 2.2827e-08, 1.5205e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.11\n",
      "probs: tensor([[7.8807e-01, 8.2704e-03, 2.9517e-08, 2.0366e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.11\n",
      "232.80890891827704\n",
      "probs: tensor([[0.2186, 0.4264, 0.2306, 0.1243]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.11\n",
      "probs: tensor([[2.1346e-02, 9.7865e-01, 3.0857e-15, 5.1793e-07]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.11\n",
      "probs: tensor([[0.1344, 0.0076, 0.3337, 0.5243]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.11\n",
      "240.0456857332716\n",
      "probs: tensor([[0.2990, 0.0985, 0.5420, 0.0605]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.11\n",
      "probs: tensor([[9.3327e-01, 1.9425e-02, 1.4479e-09, 4.7300e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.1\n",
      "probs: tensor([[8.1580e-01, 1.3819e-01, 1.3822e-10, 4.6006e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.1\n",
      "242.76783508789185\n",
      "probs: tensor([[7.3001e-03, 4.6310e-04, 8.9588e-01, 9.6360e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.1\n",
      "probs: tensor([[5.8272e-01, 4.1727e-01, 6.9509e-18, 1.8283e-05]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.1\n",
      "probs: tensor([[5.4985e-01, 4.5012e-01, 2.9169e-17, 2.7562e-05]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.1\n",
      "probs: tensor([[0.1799, 0.0292, 0.7189, 0.0720]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.1\n",
      "probs: tensor([[7.9191e-01, 5.9558e-03, 1.5952e-08, 2.0214e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.1\n",
      "probs: tensor([[8.4309e-01, 9.4453e-03, 9.4602e-09, 1.4746e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.1\n",
      "227.90429353597978\n",
      "probs: tensor([[0.0771, 0.0384, 0.8780, 0.0064]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.1\n",
      "probs: tensor([[5.9306e-01, 2.4380e-03, 1.4070e-08, 4.0450e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.1\n",
      "probs: tensor([[4.4772e-01, 1.5589e-03, 3.6294e-08, 5.5072e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.1\n",
      "probs: tensor([[7.4971e-01, 3.0579e-03, 3.7010e-09, 2.4724e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.1\n",
      "probs: tensor([[0.0294, 0.0042, 0.8873, 0.0791]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.1\n",
      "212.9621935118452\n",
      "probs: tensor([[0.1903, 0.1091, 0.5958, 0.1047]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.1\n",
      "probs: tensor([[0.1705, 0.3749, 0.4329, 0.0217]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.1\n",
      "182.59575517030584\n",
      "probs: tensor([[6.0897e-03, 1.2284e-02, 9.8155e-01, 7.2926e-05]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.1\n",
      "probs: tensor([[0.0558, 0.0217, 0.5198, 0.4027]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.1\n",
      "probs: tensor([[5.9838e-01, 2.0557e-03, 9.9365e-09, 3.9956e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.1\n",
      "probs: tensor([[4.8973e-01, 2.1410e-03, 5.9047e-08, 5.0813e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.1\n",
      "probs: tensor([[0.1506, 0.0751, 0.6381, 0.1362]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.1\n",
      "165.7014276329977\n",
      "probs: tensor([[9.3231e-03, 9.3798e-02, 8.9654e-01, 3.3420e-04]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.1\n",
      "probs: tensor([[0.1253, 0.0481, 0.7393, 0.0873]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.1\n",
      "probs: tensor([[0.2180, 0.0279, 0.5989, 0.1552]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.1\n",
      "159.35133065695126\n",
      "probs: tensor([[0.0923, 0.0126, 0.8894, 0.0056]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.1\n",
      "probs: tensor([[7.1187e-06, 9.9999e-01, 2.6553e-13, 1.6911e-11]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.1\n",
      "probs: tensor([[0.2137, 0.4669, 0.3051, 0.0143]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.1\n",
      "182.15800355177333\n",
      "probs: tensor([[0.3352, 0.0233, 0.3661, 0.2754]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.1\n",
      "probs: tensor([[9.2733e-01, 1.6269e-02, 1.0090e-09, 5.6397e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.1\n",
      "probs: tensor([[0.2503, 0.1464, 0.5629, 0.0404]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.1\n",
      "196.03797505930953\n",
      "probs: tensor([[0.1293, 0.0789, 0.7164, 0.0754]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.1\n",
      "probs: tensor([[9.7727e-01, 1.8598e-02, 4.7736e-13, 4.1352e-03]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.1\n",
      "probs: tensor([[1.2634e-01, 3.1013e-05, 5.4684e-01, 3.2679e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.1\n",
      "224.24939467295908\n",
      "probs: tensor([[0.1419, 0.0044, 0.7920, 0.0618]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.1\n",
      "probs: tensor([[0.0149, 0.0015, 0.9557, 0.0280]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.09\n",
      "probs: tensor([[8.2515e-01, 3.5090e-03, 2.9490e-09, 1.7134e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.09\n",
      "240.05181190707535\n",
      "probs: tensor([[0.0573, 0.0358, 0.8947, 0.0122]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.09\n",
      "probs: tensor([[0.0313, 0.0014, 0.9507, 0.0166]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.09\n",
      "245.59675901657852\n",
      "probs: tensor([[0.3618, 0.0994, 0.4995, 0.0392]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.09\n",
      "probs: tensor([[3.7557e-01, 7.8056e-04, 1.4471e-08, 6.2365e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.09\n",
      "probs: tensor([[3.6658e-01, 5.0763e-04, 6.6821e-09, 6.3291e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.09\n",
      "probs: tensor([[2.7528e-01, 7.8508e-04, 7.1459e-13, 7.2393e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.09\n",
      "probs: tensor([[0.2184, 0.6728, 0.0787, 0.0300]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.09\n",
      "228.49098120160897\n",
      "probs: tensor([[0.0161, 0.0175, 0.9404, 0.0260]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.09\n",
      "probs: tensor([[0.3252, 0.1792, 0.4716, 0.0240]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.09\n",
      "probs: tensor([[0.1765, 0.0240, 0.6570, 0.1425]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.09\n",
      "probs: tensor([[9.1827e-02, 4.7970e-05, 5.0347e-09, 9.0813e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.09\n",
      "230.13708010616975\n",
      "probs: tensor([[9.7148e-01, 1.4561e-02, 2.1993e-11, 1.3955e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.09\n",
      "probs: tensor([[0.0129, 0.0610, 0.9195, 0.0066]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.09\n",
      "probs: tensor([[0.0137, 0.0041, 0.9436, 0.0386]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.09\n",
      "228.75119975176094\n",
      "probs: tensor([[0.2939, 0.1257, 0.5055, 0.0749]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.09\n",
      "probs: tensor([[0.2737, 0.1633, 0.5324, 0.0306]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.09\n",
      "230.09537844764583\n",
      "probs: tensor([[0.4121, 0.4578, 0.0005, 0.1296]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.09\n",
      "probs: tensor([[9.3196e-01, 7.7195e-03, 8.5283e-10, 6.0321e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.09\n",
      "probs: tensor([[4.1092e-01, 1.1716e-01, 1.4351e-08, 4.7192e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.09\n",
      "223.6181803446406\n",
      "probs: tensor([[0.0949, 0.0811, 0.8062, 0.0178]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.09\n",
      "probs: tensor([[6.7808e-01, 1.1667e-03, 4.9497e-09, 3.2075e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.09\n",
      "probs: tensor([[3.2303e-01, 2.8641e-04, 1.1670e-08, 6.7668e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.09\n",
      "probs: tensor([[0.0546, 0.0554, 0.8868, 0.0033]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.09\n",
      "probs: tensor([[0.3943, 0.0590, 0.0929, 0.4538]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.09\n",
      "225.01807704462925\n",
      "probs: tensor([[0.3506, 0.0199, 0.1449, 0.4846]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.09\n",
      "probs: tensor([[0.1018, 0.0022, 0.4188, 0.4771]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.09\n",
      "probs: tensor([[0.2176, 0.0373, 0.5794, 0.1657]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.09\n",
      "223.72350081868058\n",
      "probs: tensor([[0.3883, 0.2559, 0.3369, 0.0189]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.09\n",
      "probs: tensor([[6.3054e-01, 1.0106e-03, 3.8459e-09, 3.6845e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.09\n",
      "probs: tensor([[3.7242e-01, 3.6414e-04, 6.4895e-09, 6.2721e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.09\n",
      "probs: tensor([[0.2223, 0.0233, 0.5209, 0.2335]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.09\n",
      "213.14653184663356\n",
      "probs: tensor([[0.0086, 0.0801, 0.9081, 0.0033]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.09\n",
      "probs: tensor([[0.3714, 0.2044, 0.3967, 0.0275]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.09\n",
      "probs: tensor([[0.0260, 0.0226, 0.9497, 0.0018]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.09\n",
      "probs: tensor([[9.4933e-01, 2.8540e-03, 1.2896e-10, 4.7821e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.09\n",
      "210.44425237920223\n",
      "probs: tensor([[0.1445, 0.0410, 0.7294, 0.0851]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.08\n",
      "probs: tensor([[0.0933, 0.0094, 0.8857, 0.0117]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.08\n",
      "probs: tensor([[0.1927, 0.0798, 0.6505, 0.0770]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.08\n",
      "probs: tensor([[9.3273e-01, 4.2299e-03, 5.8459e-10, 6.3040e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.08\n",
      "209.83611269796097\n",
      "probs: tensor([[0.2016, 0.0670, 0.6864, 0.0449]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.08\n",
      "probs: tensor([[0.1952, 0.0547, 0.6667, 0.0834]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.08\n",
      "228.9690939616733\n",
      "probs: tensor([[0.2333, 0.6532, 0.1094, 0.0042]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.08\n",
      "probs: tensor([[8.6414e-01, 2.9432e-03, 6.1880e-09, 1.3291e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.08\n",
      "probs: tensor([[0.3422, 0.0909, 0.4862, 0.0808]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.08\n",
      "229.23928362388205\n",
      "probs: tensor([[0.3194, 0.1480, 0.3548, 0.1779]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.08\n",
      "probs: tensor([[5.1814e-01, 4.8182e-01, 2.8985e-15, 4.0877e-05]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.08\n",
      "probs: tensor([[3.1160e-01, 6.8839e-01, 3.7996e-15, 1.7308e-05]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.08\n",
      "probs: tensor([[0.5465, 0.1280, 0.3126, 0.0129]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.08\n",
      "probs: tensor([[6.4956e-01, 2.7817e-01, 2.2789e-10, 7.2272e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.08\n",
      "226.39230640177396\n",
      "probs: tensor([[0.1102, 0.0099, 0.7636, 0.1163]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.08\n",
      "probs: tensor([[0.1194, 0.0040, 0.4094, 0.4672]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.08\n",
      "227.95214370718767\n",
      "probs: tensor([[0.0294, 0.0605, 0.9061, 0.0041]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.08\n",
      "probs: tensor([[1.4564e-06, 3.4823e-18, 1.6538e-23, 1.0000e+00]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.08\n",
      "probs: tensor([[0.1305, 0.0301, 0.7198, 0.1196]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.08\n",
      "233.43451527545304\n",
      "probs: tensor([[0.2074, 0.5201, 0.2642, 0.0083]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.08\n",
      "probs: tensor([[0.0223, 0.0011, 0.9426, 0.0340]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.08\n",
      "230.1380266375125\n",
      "probs: tensor([[4.5996e-02, 2.3891e-01, 7.1491e-01, 1.7909e-04]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.08\n",
      "probs: tensor([[0.2389, 0.2864, 0.4601, 0.0145]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.08\n",
      "233.48652777040928\n",
      "probs: tensor([[0.2439, 0.3257, 0.4048, 0.0256]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.08\n",
      "probs: tensor([[0.1371, 0.0490, 0.8075, 0.0064]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.08\n",
      "251.94781402018558\n",
      "probs: tensor([[0.7459, 0.0387, 0.1183, 0.0971]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.08\n",
      "probs: tensor([[9.7381e-01, 2.0726e-02, 6.5797e-11, 5.4647e-03]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.08\n",
      "254.1257739281321\n",
      "probs: tensor([[7.2936e-01, 2.7457e-02, 7.6721e-12, 2.4318e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.08\n",
      "probs: tensor([[0.4631, 0.0609, 0.0139, 0.4620]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.08\n",
      "probs: tensor([[0.3778, 0.0819, 0.3559, 0.1844]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.08\n",
      "probs: tensor([[0.1212, 0.0732, 0.7926, 0.0130]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.08\n",
      "253.66751666192758\n",
      "probs: tensor([[0.1564, 0.0418, 0.7916, 0.0102]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.08\n",
      "probs: tensor([[0.1421, 0.0524, 0.7934, 0.0121]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.08\n",
      "probs: tensor([[9.4268e-01, 3.0388e-03, 4.0935e-10, 5.4278e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.08\n",
      "251.37229841183566\n",
      "probs: tensor([[0.1802, 0.1247, 0.6336, 0.0615]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.08\n",
      "probs: tensor([[0.0895, 0.1014, 0.8065, 0.0026]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.08\n",
      "250.00874642885736\n",
      "probs: tensor([[9.9130e-02, 3.0519e-01, 5.9527e-01, 4.1718e-04]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.08\n",
      "probs: tensor([[0.2758, 0.0536, 0.6478, 0.0228]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.08\n",
      "245.05962148238328\n",
      "probs: tensor([[0.4628, 0.0657, 0.4169, 0.0546]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.08\n",
      "probs: tensor([[0.0289, 0.0352, 0.9268, 0.0090]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.08\n",
      "240.5498826315365\n",
      "probs: tensor([[0.0779, 0.0240, 0.8945, 0.0036]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.08\n",
      "probs: tensor([[0.1918, 0.0047, 0.2291, 0.5744]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.08\n",
      "probs: tensor([[2.0121e-02, 9.7988e-01, 1.6904e-24, 5.9848e-09]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.07\n",
      "probs: tensor([[6.6494e-02, 9.3351e-01, 4.6759e-26, 7.2343e-08]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.07\n",
      "probs: tensor([[0.3442, 0.2393, 0.2954, 0.1211]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.07\n",
      "probs: tensor([[8.5302e-01, 1.2885e-03, 2.6807e-10, 1.4569e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.07\n",
      "226.4510738122895\n",
      "probs: tensor([[0.1728, 0.0444, 0.6366, 0.1462]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.07\n",
      "probs: tensor([[1.1087e-02, 9.8326e-01, 5.6478e-03, 9.6436e-06]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.07\n",
      "227.69200787694544\n",
      "probs: tensor([[0.7768, 0.1242, 0.0795, 0.0195]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.07\n",
      "probs: tensor([[0.2057, 0.1017, 0.6440, 0.0487]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.07\n",
      "227.38343550534287\n",
      "probs: tensor([[0.4411, 0.1994, 0.0196, 0.3399]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.07\n",
      "probs: tensor([[0.3741, 0.2559, 0.3181, 0.0518]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.07\n",
      "probs: tensor([[0.0670, 0.0172, 0.9055, 0.0104]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.07\n",
      "226.8236977490238\n",
      "probs: tensor([[2.1800e-01, 5.1166e-01, 1.5533e-16, 2.7034e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.07\n",
      "probs: tensor([[0.0122, 0.0180, 0.9682, 0.0016]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.07\n",
      "probs: tensor([[0.0738, 0.6056, 0.3169, 0.0037]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.07\n",
      "232.4890340011773\n",
      "probs: tensor([[0.4814, 0.2616, 0.1617, 0.0952]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.07\n",
      "probs: tensor([[0.5380, 0.1811, 0.1791, 0.1019]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.07\n",
      "244.00432730410597\n",
      "probs: tensor([[3.9477e-01, 4.6953e-01, 4.3656e-07, 1.3570e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.07\n",
      "probs: tensor([[0.2477, 0.2045, 0.5017, 0.0461]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.07\n",
      "probs: tensor([[0.0916, 0.0100, 0.8791, 0.0193]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.07\n",
      "245.1616347023543\n",
      "probs: tensor([[1.4038e-01, 2.1837e-01, 6.4094e-01, 3.0774e-04]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.07\n",
      "probs: tensor([[0.1231, 0.2564, 0.6100, 0.0105]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.07\n",
      "probs: tensor([[0.1884, 0.0193, 0.7556, 0.0367]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.07\n",
      "245.68795734268866\n",
      "probs: tensor([[1.7782e-02, 1.8412e-04, 9.8199e-01, 4.3127e-05]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.07\n",
      "probs: tensor([[9.9276e-01, 3.4567e-03, 4.1308e-13, 3.7850e-03]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.07\n",
      "probs: tensor([[0.2217, 0.2399, 0.5239, 0.0146]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.07\n",
      "252.98382604412686\n",
      "probs: tensor([[0.2346, 0.0787, 0.4475, 0.2392]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.07\n",
      "probs: tensor([[0.2872, 0.2078, 0.4796, 0.0254]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.07\n",
      "245.22178463603376\n",
      "probs: tensor([[0.0772, 0.0023, 0.6815, 0.2390]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.07\n",
      "probs: tensor([[1.4721e-03, 6.3734e-07, 9.4360e-15, 9.9853e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.07\n",
      "probs: tensor([[0.3270, 0.1295, 0.4288, 0.1147]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.07\n",
      "249.17414566497467\n",
      "probs: tensor([[0.1063, 0.0165, 0.7048, 0.1725]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.07\n",
      "probs: tensor([[0.2507, 0.0049, 0.0035, 0.7409]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.07\n",
      "248.00810058969006\n",
      "probs: tensor([[0.2307, 0.2356, 0.4361, 0.0975]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.07\n",
      "probs: tensor([[0.1907, 0.5294, 0.2382, 0.0417]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.07\n",
      "248.50053903363732\n",
      "probs: tensor([[0.0205, 0.0038, 0.9125, 0.0632]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.07\n",
      "probs: tensor([[6.6132e-01, 1.5094e-04, 3.6459e-10, 3.3853e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.07\n",
      "probs: tensor([[2.6903e-01, 6.0663e-05, 7.7618e-09, 7.3091e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.07\n",
      "probs: tensor([[0.9776, 0.0129, 0.0059, 0.0036]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.07\n",
      "probs: tensor([[6.2850e-01, 1.3489e-02, 2.8574e-11, 3.5801e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.07\n",
      "229.45903302914593\n",
      "probs: tensor([[0.3009, 0.0381, 0.3503, 0.3107]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.07\n",
      "probs: tensor([[0.0109, 0.0604, 0.9263, 0.0024]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.07\n",
      "probs: tensor([[3.0043e-01, 5.3184e-05, 6.6943e-10, 6.9952e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.07\n",
      "230.61743888690438\n",
      "probs: tensor([[0.3053, 0.0325, 0.0010, 0.6612]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.07\n",
      "probs: tensor([[7.8602e-01, 2.1376e-01, 9.9347e-12, 2.1952e-04]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.07\n",
      "probs: tensor([[0.3873, 0.0282, 0.5624, 0.0221]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.07\n",
      "probs: tensor([[0.1598, 0.1941, 0.0995, 0.5467]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.07\n",
      "228.29481761296802\n",
      "probs: tensor([[0.0083, 0.0073, 0.9824, 0.0020]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.07\n",
      "probs: tensor([[0.2067, 0.1328, 0.5906, 0.0699]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.07\n",
      "229.24026204606926\n",
      "probs: tensor([[0.1595, 0.1400, 0.6689, 0.0316]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "probs: tensor([[3.8123e-01, 6.1861e-01, 7.3247e-18, 1.6081e-04]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "probs: tensor([[0.0169, 0.0080, 0.9737, 0.0015]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "probs: tensor([[0.1067, 0.0777, 0.7919, 0.0238]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "226.54044927004648\n",
      "probs: tensor([[0.3413, 0.4445, 0.2078, 0.0064]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "probs: tensor([[0.2721, 0.0023, 0.7027, 0.0229]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "probs: tensor([[0.4151, 0.0610, 0.4381, 0.0857]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "241.98657448028675\n",
      "probs: tensor([[0.4399, 0.0523, 0.1660, 0.3417]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "probs: tensor([[1.4758e-02, 4.6201e-05, 6.2489e-01, 3.6031e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "248.53521210061777\n",
      "probs: tensor([[0.0905, 0.0169, 0.8564, 0.0361]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "probs: tensor([[0.0116, 0.0100, 0.9283, 0.0501]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "probs: tensor([[1.3265e-01, 8.6735e-01, 3.6938e-17, 1.4377e-07]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "probs: tensor([[0.2784, 0.0400, 0.6419, 0.0397]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "probs: tensor([[5.6910e-05, 8.1277e-15, 4.4770e-12, 9.9994e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "245.3544200641073\n",
      "probs: tensor([[0.5441, 0.0670, 0.1349, 0.2539]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "probs: tensor([[0.1656, 0.0681, 0.7123, 0.0541]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "242.23627404435405\n",
      "probs: tensor([[0.2208, 0.2070, 0.3949, 0.1773]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "probs: tensor([[0.1421, 0.0402, 0.7297, 0.0881]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "244.8676276033265\n",
      "probs: tensor([[0.1899, 0.0170, 0.7827, 0.0104]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "probs: tensor([[9.5329e-01, 1.1250e-03, 2.9786e-11, 4.5580e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "probs: tensor([[0.1407, 0.0054, 0.5209, 0.3331]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "240.2114734377451\n",
      "probs: tensor([[7.2071e-01, 2.0622e-02, 8.4551e-14, 2.5867e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "probs: tensor([[9.8315e-01, 5.5016e-04, 2.8187e-13, 1.6302e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "probs: tensor([[9.9018e-01, 1.1714e-03, 3.4730e-13, 8.6505e-03]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "239.8551410345881\n",
      "probs: tensor([[9.8386e-01, 8.9844e-04, 8.7977e-13, 1.5239e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "probs: tensor([[6.9813e-03, 2.1966e-03, 9.9014e-01, 6.8010e-04]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "244.31427001807438\n",
      "probs: tensor([[9.8979e-01, 1.4249e-03, 4.4805e-13, 8.7858e-03]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "probs: tensor([[3.1592e-02, 1.1314e-01, 8.5483e-01, 4.3715e-04]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "probs: tensor([[4.5815e-01, 3.3479e-02, 8.3621e-06, 5.0837e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "probs: tensor([[6.9756e-01, 1.0031e-01, 4.4745e-05, 2.0209e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "235.29014944285967\n",
      "probs: tensor([[0.2466, 0.4108, 0.3369, 0.0057]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "probs: tensor([[0.0451, 0.0110, 0.9083, 0.0355]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "probs: tensor([[0.0465, 0.0010, 0.8127, 0.1398]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "probs: tensor([[9.9993e-01, 1.0144e-05, 8.5087e-15, 5.9532e-05]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "229.10822794879522\n",
      "probs: tensor([[0.1252, 0.1298, 0.6678, 0.0773]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "probs: tensor([[0.3894, 0.1948, 0.4095, 0.0063]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "231.3977795485692\n",
      "probs: tensor([[0.0314, 0.0036, 0.9182, 0.0468]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "probs: tensor([[0.0491, 0.0355, 0.9134, 0.0020]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "probs: tensor([[3.1921e-03, 5.1733e-04, 9.9591e-01, 3.8387e-04]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "229.2279759337423\n",
      "probs: tensor([[0.4444, 0.0646, 0.2510, 0.2400]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "probs: tensor([[0.0906, 0.2823, 0.6256, 0.0015]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "probs: tensor([[2.7491e-03, 9.0708e-03, 9.8816e-01, 1.8157e-05]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "229.55979082208623\n",
      "probs: tensor([[0.2632, 0.0011, 0.1414, 0.5943]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "probs: tensor([[6.7107e-02, 3.3112e-04, 8.7936e-01, 5.3199e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "243.2354476553568\n",
      "probs: tensor([[4.9949e-05, 2.9279e-09, 9.9785e-01, 2.1043e-03]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "probs: tensor([[9.7081e-01, 5.0597e-04, 1.9584e-12, 2.8679e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "probs: tensor([[0.3515, 0.1579, 0.4826, 0.0080]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "253.77570480165846\n",
      "probs: tensor([[0.4049, 0.2944, 0.1730, 0.1276]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "probs: tensor([[0.0564, 0.3799, 0.5621, 0.0016]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "254.7991459252416\n",
      "probs: tensor([[0.5823, 0.0762, 0.1417, 0.1998]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "probs: tensor([[0.4837, 0.2668, 0.1620, 0.0874]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "258.8032027466942\n",
      "probs: tensor([[0.0929, 0.0014, 0.6920, 0.2137]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "probs: tensor([[0.2307, 0.0635, 0.6354, 0.0704]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "256.2261450641362\n",
      "probs: tensor([[0.0530, 0.0740, 0.8711, 0.0019]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "probs: tensor([[3.1488e-02, 3.5735e-04, 9.2429e-01, 4.3868e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.06\n",
      "probs: tensor([[0.0318, 0.0067, 0.5253, 0.4362]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "248.66717788715064\n",
      "probs: tensor([[0.6563, 0.0214, 0.2790, 0.0432]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "probs: tensor([[6.0088e-01, 1.6133e-01, 4.8828e-08, 2.3779e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "probs: tensor([[0.7507, 0.0987, 0.0300, 0.1206]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "245.90004617893447\n",
      "probs: tensor([[0.4407, 0.0857, 0.4250, 0.0487]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "probs: tensor([[4.2879e-03, 2.0817e-04, 9.6080e-01, 3.4701e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "probs: tensor([[0.3251, 0.1976, 0.4584, 0.0189]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "239.07993682312446\n",
      "probs: tensor([[0.0827, 0.8250, 0.0908, 0.0015]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "probs: tensor([[9.8988e-01, 2.5484e-03, 6.7613e-03, 8.0963e-04]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "probs: tensor([[1.6707e-02, 4.8410e-01, 7.3823e-06, 4.9918e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "probs: tensor([[1.9965e-01, 2.5496e-06, 6.1916e-01, 1.8119e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "probs: tensor([[9.9399e-01, 5.8451e-03, 5.6594e-14, 1.6704e-04]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "221.3867181250097\n",
      "probs: tensor([[0.0435, 0.0488, 0.8545, 0.0532]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "probs: tensor([[0.0445, 0.0072, 0.8673, 0.0810]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "224.20974813141112\n",
      "probs: tensor([[0.1279, 0.0044, 0.6988, 0.1689]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "probs: tensor([[0.0894, 0.0085, 0.8188, 0.0833]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "231.9013836438612\n",
      "probs: tensor([[0.3415, 0.1619, 0.4904, 0.0063]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "probs: tensor([[2.1433e-07, 5.5144e-09, 2.5749e-01, 7.4251e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "probs: tensor([[9.6666e-01, 2.5118e-04, 3.2199e-12, 3.3093e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "232.04413300148607\n",
      "probs: tensor([[0.3608, 0.0482, 0.5803, 0.0107]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "probs: tensor([[5.4672e-01, 5.3537e-05, 9.3917e-11, 4.5322e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "probs: tensor([[0.6403, 0.0016, 0.3396, 0.0185]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "probs: tensor([[3.8889e-02, 4.1715e-05, 8.0374e-01, 1.5733e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "probs: tensor([[1.6460e-01, 8.3540e-01, 2.5811e-18, 2.2421e-08]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "230.47881280755797\n",
      "probs: tensor([[4.6599e-02, 2.1070e-03, 9.5096e-01, 3.3391e-04]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "probs: tensor([[0.7004, 0.1173, 0.1594, 0.0229]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "244.61456266923983\n",
      "probs: tensor([[0.7337, 0.0155, 0.2092, 0.0415]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "probs: tensor([[3.5681e-04, 3.8360e-07, 9.7870e-01, 2.0944e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "probs: tensor([[9.9811e-01, 1.3537e-03, 9.8981e-15, 5.3338e-04]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "244.53134898162142\n",
      "probs: tensor([[5.9227e-02, 6.5156e-01, 2.8894e-01, 2.7223e-04]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "probs: tensor([[0.3553, 0.0089, 0.6306, 0.0052]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "probs: tensor([[9.6147e-01, 1.5976e-04, 2.2737e-12, 3.8368e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "240.2394575451364\n",
      "probs: tensor([[9.1482e-05, 9.9957e-01, 3.3608e-04, 1.9042e-11]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "probs: tensor([[9.7702e-01, 2.1618e-02, 6.1866e-15, 1.3591e-03]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "238.81856095274208\n",
      "probs: tensor([[0.5648, 0.1521, 0.0859, 0.1972]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "probs: tensor([[0.4059, 0.0282, 0.5478, 0.0181]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "246.71225772641282\n",
      "probs: tensor([[0.1195, 0.0718, 0.8007, 0.0080]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "probs: tensor([[0.0484, 0.0019, 0.9357, 0.0139]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "probs: tensor([[7.4053e-01, 5.4766e-05, 1.1250e-11, 2.5942e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "probs: tensor([[6.3077e-01, 4.5925e-05, 1.0473e-10, 3.6919e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "243.47686693255577\n",
      "probs: tensor([[9.9778e-01, 3.8201e-04, 1.0490e-13, 1.8379e-03]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "probs: tensor([[2.2724e-03, 2.2734e-03, 9.9535e-01, 9.9970e-05]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "244.94413999253055\n",
      "probs: tensor([[0.1375, 0.3842, 0.4763, 0.0020]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "probs: tensor([[0.0576, 0.0726, 0.8676, 0.0023]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "248.49374224666727\n",
      "probs: tensor([[0.4547, 0.1363, 0.3922, 0.0169]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "probs: tensor([[0.7476, 0.0378, 0.0050, 0.2096]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "248.01927688192313\n",
      "probs: tensor([[0.3690, 0.0036, 0.1370, 0.4904]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "probs: tensor([[3.5687e-03, 1.2821e-01, 8.6822e-01, 3.1320e-08]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "246.79916042922045\n",
      "probs: tensor([[9.0621e-01, 1.1436e-02, 1.5467e-08, 8.2351e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "probs: tensor([[9.8669e-01, 1.3311e-04, 2.9125e-13, 1.3177e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "probs: tensor([[0.0996, 0.0220, 0.8587, 0.0196]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "probs: tensor([[0.3866, 0.4565, 0.1083, 0.0486]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "246.16531502905985\n",
      "probs: tensor([[1.3514e-02, 1.2542e-03, 9.8484e-01, 3.9349e-04]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "probs: tensor([[0.1129, 0.1129, 0.7440, 0.0301]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "probs: tensor([[3.6219e-04, 3.4952e-06, 9.9803e-01, 1.6039e-03]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "243.38188047571015\n",
      "probs: tensor([[0.3152, 0.0118, 0.5637, 0.1093]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "probs: tensor([[0.2510, 0.6006, 0.1444, 0.0040]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "247.31020380866184\n",
      "probs: tensor([[0.4502, 0.2124, 0.2803, 0.0571]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "probs: tensor([[0.0236, 0.0147, 0.9550, 0.0068]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "probs: tensor([[7.6217e-06, 1.3629e-12, 1.8892e-13, 9.9999e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "246.71275590923105\n",
      "probs: tensor([[0.1555, 0.2267, 0.6036, 0.0141]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "probs: tensor([[4.1482e-02, 4.4009e-03, 9.5385e-01, 2.6753e-04]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "250.36000699373744\n",
      "probs: tensor([[0.0690, 0.0007, 0.5253, 0.4049]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "probs: tensor([[9.9854e-01, 1.8249e-04, 1.0320e-13, 1.2816e-03]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "probs: tensor([[0.1619, 0.3055, 0.5273, 0.0053]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "252.8182470405262\n",
      "probs: tensor([[0.3835, 0.5532, 0.0337, 0.0296]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "probs: tensor([[5.3931e-02, 1.2499e-07, 3.9728e-12, 9.4607e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.05\n",
      "probs: tensor([[9.9897e-01, 1.4975e-04, 6.0703e-15, 8.7655e-04]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.04\n",
      "253.8583442513771\n",
      "probs: tensor([[0.3901, 0.0168, 0.3169, 0.2762]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.04\n",
      "probs: tensor([[3.9082e-01, 6.1372e-06, 1.3846e-11, 6.0917e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.04\n",
      "probs: tensor([[6.5795e-01, 1.8344e-05, 1.8772e-11, 3.4203e-01]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.04\n",
      "probs: tensor([[0.0762, 0.0049, 0.9129, 0.0060]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.04\n",
      "probs: tensor([[9.9917e-01, 1.5315e-04, 3.2209e-13, 6.7730e-04]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.04\n",
      "236.32547293607126\n",
      "probs: tensor([[0.0174, 0.0847, 0.8890, 0.0089]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.04\n",
      "probs: tensor([[2.2301e-03, 1.1986e-04, 9.4736e-01, 5.0290e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.04\n",
      "probs: tensor([[6.7252e-07, 1.0000e+00, 2.2224e-33, 2.9332e-16]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.04\n",
      "233.98083128172578\n",
      "probs: tensor([[6.0058e-02, 1.1541e-02, 9.2810e-01, 2.9667e-04]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.04\n",
      "probs: tensor([[0.0032, 0.0038, 0.0465, 0.9465]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.04\n",
      "227.0740721931391\n",
      "probs: tensor([[1.0784e-01, 3.7089e-01, 5.2118e-01, 9.0077e-05]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.04\n",
      "probs: tensor([[9.1605e-02, 2.8746e-02, 8.7942e-01, 2.2709e-04]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.04\n",
      "probs: tensor([[9.3290e-01, 8.1341e-05, 1.1548e-11, 6.7014e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.04\n",
      "228.0668648370835\n",
      "probs: tensor([[0.0362, 0.0039, 0.8955, 0.0644]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.04\n",
      "probs: tensor([[0.5957, 0.0094, 0.3230, 0.0719]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.04\n",
      "231.86127932619425\n",
      "probs: tensor([[0.1388, 0.0101, 0.8299, 0.0212]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.04\n",
      "probs: tensor([[0.0475, 0.0054, 0.9426, 0.0045]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.04\n",
      "240.46330094600225\n",
      "probs: tensor([[0.7962, 0.1045, 0.0425, 0.0567]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.04\n",
      "probs: tensor([[2.3047e-01, 2.7369e-02, 7.4176e-01, 4.0406e-04]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.04\n",
      "probs: tensor([[2.0608e-03, 1.0167e-04, 9.8677e-01, 1.1068e-02]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.04\n",
      "237.30410010777078\n",
      "probs: tensor([[0.0346, 0.0117, 0.9046, 0.0490]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.04\n",
      "probs: tensor([[0.0491, 0.0420, 0.9000, 0.0089]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.04\n",
      "probs: tensor([[0.8969, 0.0289, 0.0068, 0.0675]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.04\n",
      "243.059628752416\n",
      "probs: tensor([[0.1024, 0.0078, 0.7542, 0.1356]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.04\n",
      "probs: tensor([[0.6405, 0.0999, 0.2548, 0.0048]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.04\n",
      "197.74356068851714\n",
      "probs: tensor([[0.7127, 0.0593, 0.2155, 0.0125]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.04\n",
      "probs: tensor([[0.0887, 0.1519, 0.0358, 0.7236]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.04\n",
      "probs: tensor([[0.0583, 0.0059, 0.8175, 0.1183]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.04\n",
      "187.69058576200854\n",
      "probs: tensor([[0.0927, 0.0151, 0.8877, 0.0045]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.04\n",
      "probs: tensor([[0.1141, 0.0261, 0.8200, 0.0398]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.04\n",
      "190.29567186244353\n",
      "probs: tensor([[0.8308, 0.0181, 0.1473, 0.0039]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.04\n",
      "probs: tensor([[0.6354, 0.0063, 0.0637, 0.2945]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.04\n",
      "probs: tensor([[1.7639e-02, 4.8927e-03, 9.7663e-01, 8.3693e-04]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "alpha: 0.04\n",
      "196.8817672348762\n",
      "probs: tensor([[0.1638, 0.0211, 0.8104, 0.0047]], grad_fn=<ExpBackward0>)\n",
      "alpha: 0.04\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make('LunarLander-v2')\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.n\n",
    "\n",
    "agent = SAC_discrete_for_lunar(state_dim, action_dim)\n",
    "\n",
    "episode_n = 500\n",
    "\n",
    "total_rewards = []\n",
    "loss1 = []\n",
    "grads1 = []\n",
    "loss2 = []\n",
    "grads2 = []\n",
    "counter = 0\n",
    "for episode in range(episode_n):\n",
    "\n",
    "    total_reward = 0\n",
    "    state, info = env.reset()\n",
    "    \n",
    "    for i in range(1000):\n",
    "        action = agent.get_action(state)\n",
    "        \n",
    "        next_state, reward, terminated, truncated, info = env.step(action)\n",
    "        \n",
    "        agent.add_five(state, action, reward, terminated or truncated, next_state)\n",
    "        counter += 1\n",
    "\n",
    "        if counter % 1 == 0:\n",
    "            _mean_q1_loss, _mean_q2_loss, _mean_q1_grads, _mean_q2_grads = agent.fit()\n",
    "            loss1.append(_mean_q1_loss)\n",
    "            grads1.append(_mean_q1_grads)\n",
    "            loss2.append(_mean_q2_loss)\n",
    "            grads2.append(_mean_q2_grads)\n",
    "    \n",
    "        total_reward += reward\n",
    "        state = next_state\n",
    "\n",
    "        if terminated or truncated:\n",
    "            break\n",
    "\n",
    "    \n",
    "        \n",
    "    total_rewards.append(total_reward)\n",
    "    if episode % 2 == 0:\n",
    "        print(np.mean(total_rewards[-10:]))\n",
    "    \n",
    "\n",
    "plt.plot(total_rewards)\n",
    "plt.title('Total Rewards')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "plt.plot(loss1)\n",
    "plt.title('Q Loss1')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "plt.plot(grads1)\n",
    "plt.title('Q grads1')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "plt.plot(loss2)\n",
    "plt.title('Q Loss2')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "plt.plot(grads2)\n",
    "plt.title('Q grads2')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f9703b7-4591-494b-8ed2-b164351f6463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0474, 0.9526]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = nn.LogSoftmax(dim=1)\n",
    "torch.exp(s(torch.tensor([[-2.0, 1.0]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f734606e-818a-41fa-84eb-963b2dab11a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/artem/atari_games/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257.99014797953294\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('LunarLander-v2', render_mode=\"human\")\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.n\n",
    "\n",
    "\n",
    "total_reward = 0\n",
    "state, info = env.reset()\n",
    "\n",
    "for i in range(1000):\n",
    "    action = agent.get_action(state)\n",
    "    \n",
    "    next_state, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "    env.render()\n",
    "\n",
    "    total_reward += reward\n",
    "    state = next_state\n",
    "\n",
    "    if terminated or truncated:\n",
    "        break\n",
    "\n",
    "print(total_reward)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
